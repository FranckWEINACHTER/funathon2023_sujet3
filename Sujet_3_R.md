# Funathon 2023 - Sujet 3

Responsables :
- Julie Sixou, D2E
- Antoine Palazzolo, SSP Lab
- Thomas Faria, SSP Lab

# Habitudes alimentaires √† partir des donn√©es INCA

## Avant de commencer...

Ce sujet est disponible dans 2 langages : R et Python.
Ce notebook correspond √† la version R, qui est la plus r√©duite des deux. En effet, la partie 3 sur les premiers pas en Machine Learning est sp√©cifique √† Python.

Il s'agit l√† principalement d'une initiation √† l'analyse de donn√©es et √† la data visualization, √† travers l'√©tude des donn√©es de consommations et habitudes alimentaires de l'[√©tude INCA 3](https://www.data.gouv.fr/fr/datasets/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/).
Le sujet est constitu√©e de 3 parties distinctes et ind√©pendantes :
- Analyse exploratoire des donn√©es et visualisations
- Clustering d'individus : ACP, K-moyennes, Clustering Ascendant Hi√©rarchique
- __Absente du sujet en R__ : _Pr√©diction de l'IMC : premiers pas vers les m√©thodes de ML supervis√©_

Il est √©galement possible de ne faire qu'une ou deux parties du sujet. A noter que les corrig√©s pr√©sent√©s dans le sujet ne sont qu'une suggestion de comment r√©pondre aux questions pos√©es, mais qu'il existe √©videmment d'autres mani√®res de faire, parfois m√™me bien meilleures.

Si jamais vous n'√™tes pas familiers avec R, nous ne saurions que trop vous recommander de jeter un oeil aux ressources suivantes :
- D√©buter avec R : https://www.utilitr.org/
- Bonnes pratiques en R : https://www.pratiques.utilitr.org/

Pour en savoir plus sur les donn√©es utilis√©es pour ce sujet et sur le contexte de l'√©tude : https://www.data.gouv.fr/fr/datasets/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/

Pour lire la documentation associ√©e aux donn√©es : https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf

### Imports

Ex√©cutez √† pr√©sent la cellule ci-dessous pour installer les packages n√©cessaires au sujet :


```R
# Lecture du fichier requirements.txt
requirements <- readLines("requirements_R.txt")

# Installation des packages
for (package in requirements) {
  install.packages(package)
}
```

    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    


Ex√©cutez √©galement les cellules ci-dessous pour importer l'ensemble des jeux de donn√©es n√©cessaires √† l'√©tude :


```R
library(aws.s3)
library(dplyr)
library(readr)
```

    
    Attaching package: ‚Äòdplyr‚Äô
    
    
    The following objects are masked from ‚Äòpackage:stats‚Äô:
    
        filter, lag
    
    
    The following objects are masked from ‚Äòpackage:base‚Äô:
    
        intersect, setdiff, setequal, union
    
    


#### Imports des donn√©es avec s3

A favoriser, en utilisant les donn√©es d√©j√† import√©es sur le Datalab


```R
bucket <- "projet-funathon"
path_data <- "2023/sujet3/diffusion"
```


```R
description_indiv <- s3read_using(read_delim, object = paste(path_data, "description-indiv.csv", sep="/"), bucket = bucket, opts = list('region'=''), show_col_types = FALSE)
habitudes_indiv <- s3read_using(read_delim, object = paste(path_data, "habitudes-indiv.csv", sep="/"), bucket = bucket, opts = list('region'=''), show_col_types = FALSE)
actphys_sedent <- s3read_using(read_delim, object = paste(path_data, "actphys-sedent.csv", sep="/"), bucket = bucket, opts = list('region'=''), show_col_types = FALSE)
fpq <- s3read_using(read_delim, object = paste(path_data, "fpq.csv", sep="/"), bucket = bucket, opts = list('region'=''), show_col_types = FALSE)
```

    Warning message:
    ‚Äú[1m[22mOne or more parsing issues, call `problems()` on your data frame for details,
    e.g.:
      dat <- vroom(...)
      problems(dat)‚Äù
    Warning message:
    ‚Äú[1m[22mOne or more parsing issues, call `problems()` on your data frame for details,
    e.g.:
      dat <- vroom(...)
      problems(dat)‚Äù
    Warning message:
    ‚Äú[1m[22mOne or more parsing issues, call `problems()` on your data frame for details,
    e.g.:
      dat <- vroom(...)
      problems(dat)‚Äù



```R
head(description_indiv)
str(description_indiv)
```


<table class="dataframe">
<caption>A tibble: 6 √ó 185</caption>
<thead>
	<tr><th scope=col>NOMEN</th><th scope=col>NOIND</th><th scope=col>ech</th><th scope=col>enf_allaite</th><th scope=col>pop1</th><th scope=col>pop2</th><th scope=col>pop3</th><th scope=col>pond_indiv_adu_pop1</th><th scope=col>pond_indiv_enf_pop1</th><th scope=col>pond_indiv_adu_pop2</th><th scope=col>‚ãØ</th><th scope=col>fume_age_debut_nsp</th><th scope=col>fume_age_arret</th><th scope=col>fume_age_arret_nsp</th><th scope=col>bmr_kcal</th><th scope=col>sousest0</th><th scope=col>surest0</th><th scope=col>sousest1</th><th scope=col>sousest3</th><th scope=col>sousext</th><th scope=col>surext</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>‚ãØ</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>1101001</td><td>110100101</td><td>1</td><td>NA</td><td>1</td><td>1</td><td>1</td><td>11415.498</td><td>NA</td><td>18553.734</td><td>‚ãØ</td><td>NA</td><td>NA</td><td>NA</td><td>1378.093</td><td> 0</td><td> 0</td><td> 0</td><td>NA</td><td> 0</td><td> 0</td></tr>
	<tr><td>1101007</td><td>110100701</td><td>1</td><td>NA</td><td>1</td><td>1</td><td>1</td><td> 4644.245</td><td>NA</td><td> 4656.461</td><td>‚ãØ</td><td>NA</td><td>NA</td><td>NA</td><td>1352.780</td><td> 1</td><td> 0</td><td> 1</td><td>NA</td><td> 0</td><td> 0</td></tr>
	<tr><td>1101008</td><td>110100801</td><td>1</td><td>NA</td><td>1</td><td>1</td><td>1</td><td> 6016.880</td><td>NA</td><td> 6307.757</td><td>‚ãØ</td><td>NA</td><td>33</td><td>NA</td><td>1630.974</td><td> 0</td><td> 0</td><td> 0</td><td>NA</td><td> 0</td><td> 0</td></tr>
	<tr><td>1101012</td><td>110101201</td><td>1</td><td>NA</td><td>1</td><td>1</td><td>1</td><td> 1782.446</td><td>NA</td><td> 2041.063</td><td>‚ãØ</td><td>NA</td><td>NA</td><td>NA</td><td>1749.460</td><td> 0</td><td> 0</td><td> 0</td><td>NA</td><td> 0</td><td> 0</td></tr>
	<tr><td>1101014</td><td>110101401</td><td>1</td><td>NA</td><td>1</td><td>1</td><td>1</td><td> 2359.106</td><td>NA</td><td> 2455.424</td><td>‚ãØ</td><td>NA</td><td>NA</td><td>NA</td><td>1090.112</td><td> 0</td><td> 0</td><td> 0</td><td>NA</td><td> 0</td><td> 0</td></tr>
	<tr><td>1101016</td><td>110101601</td><td>1</td><td>NA</td><td>1</td><td>1</td><td>0</td><td>13623.502</td><td>NA</td><td>16412.590</td><td>‚ãØ</td><td>NA</td><td>NA</td><td>NA</td><td>      NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>
</tbody>
</table>



    spc_tbl_ [5,855 √ó 185] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
     $ NOMEN                        : num [1:5855] 1101001 1101007 1101008 1101012 1101014 ...
     $ NOIND                        : num [1:5855] 1.1e+08 1.1e+08 1.1e+08 1.1e+08 1.1e+08 ...
     $ ech                          : num [1:5855] 1 1 1 1 1 1 1 1 1 1 ...
     $ enf_allaite                  : num [1:5855] NA NA NA NA NA NA NA NA NA NA ...
     $ pop1                         : num [1:5855] 1 1 1 1 1 1 1 1 1 1 ...
     $ pop2                         : num [1:5855] 1 1 1 1 1 1 1 0 1 1 ...
     $ pop3                         : num [1:5855] 1 1 1 1 1 0 0 0 1 1 ...
     $ pond_indiv_adu_pop1          : num [1:5855] 11415 4644 6017 1782 2359 ...
     $ pond_indiv_enf_pop1          : num [1:5855] NA NA NA NA NA NA NA NA NA NA ...
     $ pond_indiv_adu_pop2          : num [1:5855] 18554 4656 6308 2041 2455 ...
     $ pond_indiv_enf_pop2          : num [1:5855] NA NA NA NA NA NA NA NA NA NA ...
     $ pond_indiv_adu_pop3          : num [1:5855] 20744 6559 11348 2783 5051 ...
     $ pond_indiv_enf_pop3          : num [1:5855] NA NA NA NA NA NA NA NA NA NA ...
     $ pond_men_pop1                : num [1:5855] 397 1562 438 1612 1671 ...
     $ pond_men_pop2                : num [1:5855] 562 1679 613 1682 1966 ...
     $ zae                          : chr [1:5855] "Z01091" "Z01091" "Z01091" "Z01091" ...
     $ strate                       : num [1:5855] 6 6 6 6 6 6 6 1 3 3 ...
     $ fpc1                         : num [1:5855] 0.0383 0.0383 0.0383 0.0383 0.0383 ...
     $ fpc2                         : num [1:5855] 0.166 0.166 0.166 0.166 0.166 ...
     $ fpc3                         : num [1:5855] 0.333 0.5 0.5 1 0.5 ...
     $ saison_pop1                  : num [1:5855] 1 1 1 1 1 3 3 2 1 2 ...
     $ saison_pop2                  : num [1:5855] 1 1 1 1 1 3 3 NA 2 2 ...
     $ saison_pop3                  : num [1:5855] 1 1 1 1 3 NA NA NA 1 2 ...
     $ region_adm_12cl              : num [1:5855] 9 9 9 9 9 9 9 6 9 9 ...
     $ region_inca3                 : num [1:5855] 6 6 6 6 6 6 6 1 3 3 ...
     $ agglo_5cl                    : num [1:5855] 1 1 1 1 1 1 1 1 2 2 ...
     $ sex_PS                       : num [1:5855] 1 2 1 1 2 2 1 1 1 1 ...
     $ tage_PS                      : num [1:5855] 7 8 8 8 9 8 7 8 8 9 ...
     $ tage_PS_mois                 : num [1:5855] NA NA NA NA NA NA NA NA NA NA ...
     $ lien_rep_enf                 : num [1:5855] NA NA NA NA NA NA NA NA NA NA ...
     $ diplome_interv               : num [1:5855] 7 7 7 10 7 3 9 11 7 6 ...
     $ etude_4cl_interv             : num [1:5855] 1 1 1 3 1 1 2 4 1 1 ...
     $ situ_prof_5cl_interv         : num [1:5855] 3 1 1 1 4 1 1 1 2 4 ...
     $ atrav_interv                 : num [1:5855] 2 NA NA NA 1 NA NA NA 1 1 ...
     $ trav_nuit_interv             : num [1:5855] NA 4 4 4 NA 4 4 4 NA NA ...
     $ trav_nuit_2cl_interv         : num [1:5855] NA 2 2 2 NA 2 2 2 NA NA ...
     $ PCS_8cl_interv               : num [1:5855] 8 1 2 1 7 1 1 5 2 7 ...
     $ PCS_4cl_interv               : num [1:5855] 4 1 1 1 4 1 1 3 1 4 ...
     $ tps_travail_interv           : num [1:5855] NA 2 1 1 1 1 1 1 1 1 ...
     $ vacances_interv              : num [1:5855] 2 1 1 1 1 2 1 1 2 2 ...
     $ interv_PR                    : num [1:5855] 0 0 1 1 0 0 1 1 0 1 ...
     $ sex_PR                       : num [1:5855] 1 1 1 1 1 1 1 1 2 1 ...
     $ tage_PR                      : num [1:5855] 2 2 2 2 3 1 1 2 2 3 ...
     $ lien_interv_PR               : num [1:5855] 2 1 NA NA 1 1 NA NA 1 NA ...
     $ lien_PS_PR                   : num [1:5855] 2 1 NA NA 1 1 NA NA 1 NA ...
     $ diplome_PR                   : num [1:5855] 7 7 7 10 3 8 9 11 2 6 ...
     $ etude_4cl_PR                 : num [1:5855] 1 1 1 3 1 2 2 4 1 1 ...
     $ atrav_PR                     : num [1:5855] NA 1 NA NA 1 NA NA NA 1 1 ...
     $ PCS_8cl_PR                   : num [1:5855] 2 7 2 1 7 2 1 5 7 7 ...
     $ PCS_4cl_PR                   : num [1:5855] 1 4 1 1 4 1 1 3 4 4 ...
     $ tps_travail_PR               : num [1:5855] 1 1 1 1 1 1 1 1 1 1 ...
     $ stat_log_2cl                 : num [1:5855] 2 1 1 2 1 2 2 2 1 1 ...
     $ soins                        : num [1:5855] 2 2 2 2 2 2 2 2 1 2 ...
     $ situ_fin_3cl                 : num [1:5855] 2 1 1 1 2 2 1 1 2 2 ...
     $ revenu                       : num [1:5855] 12 11 11 11 6 12 11 12 6 8 ...
     $ RUC_4cl                      : num [1:5855] 3 4 2 4 1 3 2 2 1 2 ...
     $ nbpers                       : num [1:5855] 4 2 4 1 2 4 4 6 2 2 ...
     $ nbadu                        : num [1:5855] 3 2 2 1 2 2 2 3 2 2 ...
     $ nbenf                        : num [1:5855] 1 0 2 0 0 2 2 3 0 0 ...
     $ situ_alim_statut             : num [1:5855] 1 1 1 1 1 1 1 1 3 2 ...
     $ IA_statut                    : num [1:5855] 0 0 0 0 0 0 0 0 2 0 ...
     $ IA_score                     : num [1:5855] NA NA NA NA NA ...
     $ taille_m                     : num [1:5855] 168 166 162 177 152 158 174 186 168 173 ...
     $ taille_d                     : num [1:5855] NA NA NA NA NA NA NA NA NA NA ...
     $ taille                       : num [1:5855] 168 166 162 177 152 158 174 186 168 173 ...
     $ poids_m                      : num [1:5855] 51.6 65.1 78.6 81.9 51.8 NA 79.5 92 59.1 85.6 ...
     $ poids_d                      : num [1:5855] NA NA NA NA NA 60 NA NA NA NA ...
     $ poids                        : num [1:5855] 51.6 65.1 78.6 81.9 51.8 ...
     $ imc                          : num [1:5855] 18.3 23.6 29.9 26.1 22.4 ...
     $ statnut                      : num [1:5855] 0 1 3 3 1 1 3 3 1 3 ...
     $ maladie_allergie_alim        : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ intoall_confirm_med          : num [1:5855] NA NA NA NA NA NA NA NA NA NA ...
     $ regime_vegetarien            : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ regime_allergie              : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ regime_maigrir_med           : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ regime_maigrir_choix         : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ regime_autre_med             : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ regime_raisonmed_libelle     : chr [1:5855] NA NA NA NA ...
     $ regime_poidsstable           : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ regime_forme                 : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ regime_autreraison           : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ regime_non                   : num [1:5855] 1 1 1 1 1 1 1 NA 1 1 ...
     $ veget_viande                 : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ veget_prodmer                : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ veget_prodlait               : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ veget_oeuf                   : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ veget_miel                   : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ veget_autre_alim             : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ veget_autre_alim_libelle     : logi [1:5855] NA NA NA NA NA NA ...
     $ allergie_laitvache           : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ allergie_prepainfsoja        : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ allergie_prepainfamande      : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ allergie_gluten              : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ allergie_farineble           : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ allergie_lupin               : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ allergie_arachide            : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ allergie_fruitcoque          : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ allergie_fruitcoque_libelle  : chr [1:5855] NA NA NA NA ...
     $ allergie_oeuf                : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
      [list output truncated]
     - attr(*, "spec")=
      .. cols(
      ..   NOMEN = [32mcol_double()[39m,
      ..   NOIND = [32mcol_double()[39m,
      ..   ech = [32mcol_double()[39m,
      ..   enf_allaite = [32mcol_double()[39m,
      ..   pop1 = [32mcol_double()[39m,
      ..   pop2 = [32mcol_double()[39m,
      ..   pop3 = [32mcol_double()[39m,
      ..   pond_indiv_adu_pop1 = [32mcol_double()[39m,
      ..   pond_indiv_enf_pop1 = [32mcol_double()[39m,
      ..   pond_indiv_adu_pop2 = [32mcol_double()[39m,
      ..   pond_indiv_enf_pop2 = [32mcol_double()[39m,
      ..   pond_indiv_adu_pop3 = [32mcol_double()[39m,
      ..   pond_indiv_enf_pop3 = [32mcol_double()[39m,
      ..   pond_men_pop1 = [32mcol_double()[39m,
      ..   pond_men_pop2 = [32mcol_double()[39m,
      ..   zae = [31mcol_character()[39m,
      ..   strate = [32mcol_double()[39m,
      ..   fpc1 = [32mcol_double()[39m,
      ..   fpc2 = [32mcol_double()[39m,
      ..   fpc3 = [32mcol_double()[39m,
      ..   saison_pop1 = [32mcol_double()[39m,
      ..   saison_pop2 = [32mcol_double()[39m,
      ..   saison_pop3 = [32mcol_double()[39m,
      ..   region_adm_12cl = [32mcol_double()[39m,
      ..   region_inca3 = [32mcol_double()[39m,
      ..   agglo_5cl = [32mcol_double()[39m,
      ..   sex_PS = [32mcol_double()[39m,
      ..   tage_PS = [32mcol_double()[39m,
      ..   tage_PS_mois = [32mcol_double()[39m,
      ..   lien_rep_enf = [32mcol_double()[39m,
      ..   diplome_interv = [32mcol_double()[39m,
      ..   etude_4cl_interv = [32mcol_double()[39m,
      ..   situ_prof_5cl_interv = [32mcol_double()[39m,
      ..   atrav_interv = [32mcol_double()[39m,
      ..   trav_nuit_interv = [32mcol_double()[39m,
      ..   trav_nuit_2cl_interv = [32mcol_double()[39m,
      ..   PCS_8cl_interv = [32mcol_double()[39m,
      ..   PCS_4cl_interv = [32mcol_double()[39m,
      ..   tps_travail_interv = [32mcol_double()[39m,
      ..   vacances_interv = [32mcol_double()[39m,
      ..   interv_PR = [32mcol_double()[39m,
      ..   sex_PR = [32mcol_double()[39m,
      ..   tage_PR = [32mcol_double()[39m,
      ..   lien_interv_PR = [32mcol_double()[39m,
      ..   lien_PS_PR = [32mcol_double()[39m,
      ..   diplome_PR = [32mcol_double()[39m,
      ..   etude_4cl_PR = [32mcol_double()[39m,
      ..   atrav_PR = [32mcol_double()[39m,
      ..   PCS_8cl_PR = [32mcol_double()[39m,
      ..   PCS_4cl_PR = [32mcol_double()[39m,
      ..   tps_travail_PR = [32mcol_double()[39m,
      ..   stat_log_2cl = [32mcol_double()[39m,
      ..   soins = [32mcol_double()[39m,
      ..   situ_fin_3cl = [32mcol_double()[39m,
      ..   revenu = [32mcol_double()[39m,
      ..   RUC_4cl = [32mcol_double()[39m,
      ..   nbpers = [32mcol_double()[39m,
      ..   nbadu = [32mcol_double()[39m,
      ..   nbenf = [32mcol_double()[39m,
      ..   situ_alim_statut = [32mcol_double()[39m,
      ..   IA_statut = [32mcol_double()[39m,
      ..   IA_score = [32mcol_double()[39m,
      ..   taille_m = [32mcol_double()[39m,
      ..   taille_d = [32mcol_double()[39m,
      ..   taille = [32mcol_double()[39m,
      ..   poids_m = [32mcol_double()[39m,
      ..   poids_d = [32mcol_double()[39m,
      ..   poids = [32mcol_double()[39m,
      ..   imc = [32mcol_double()[39m,
      ..   statnut = [32mcol_double()[39m,
      ..   maladie_allergie_alim = [32mcol_double()[39m,
      ..   intoall_confirm_med = [32mcol_double()[39m,
      ..   regime_vegetarien = [32mcol_double()[39m,
      ..   regime_allergie = [32mcol_double()[39m,
      ..   regime_maigrir_med = [32mcol_double()[39m,
      ..   regime_maigrir_choix = [32mcol_double()[39m,
      ..   regime_autre_med = [32mcol_double()[39m,
      ..   regime_raisonmed_libelle = [31mcol_character()[39m,
      ..   regime_poidsstable = [32mcol_double()[39m,
      ..   regime_forme = [32mcol_double()[39m,
      ..   regime_autreraison = [32mcol_double()[39m,
      ..   regime_non = [32mcol_double()[39m,
      ..   veget_viande = [32mcol_double()[39m,
      ..   veget_prodmer = [32mcol_double()[39m,
      ..   veget_prodlait = [32mcol_double()[39m,
      ..   veget_oeuf = [32mcol_double()[39m,
      ..   veget_miel = [32mcol_double()[39m,
      ..   veget_autre_alim = [32mcol_double()[39m,
      ..   veget_autre_alim_libelle = [33mcol_logical()[39m,
      ..   allergie_laitvache = [32mcol_double()[39m,
      ..   allergie_prepainfsoja = [32mcol_double()[39m,
      ..   allergie_prepainfamande = [32mcol_double()[39m,
      ..   allergie_gluten = [32mcol_double()[39m,
      ..   allergie_farineble = [32mcol_double()[39m,
      ..   allergie_lupin = [32mcol_double()[39m,
      ..   allergie_arachide = [32mcol_double()[39m,
      ..   allergie_fruitcoque = [32mcol_double()[39m,
      ..   allergie_fruitcoque_libelle = [31mcol_character()[39m,
      ..   allergie_oeuf = [32mcol_double()[39m,
      ..   allergie_poisson = [32mcol_double()[39m,
      ..   allergie_crustace = [32mcol_double()[39m,
      ..   allergie_mollusque = [32mcol_double()[39m,
      ..   allergie_soja = [32mcol_double()[39m,
      ..   allergie_sesame = [32mcol_double()[39m,
      ..   allergie_moutarde = [32mcol_double()[39m,
      ..   allergie_sulfite = [32mcol_double()[39m,
      ..   allergie_celeri = [32mcol_double()[39m,
      ..   allergie_autres_fruitleg = [32mcol_double()[39m,
      ..   allergie_autres_fl_libelle = [31mcol_character()[39m,
      ..   allergie_autresalim = [32mcol_double()[39m,
      ..   allergie_autresalim_libelle = [31mcol_character()[39m,
      ..   allergie_nondetermine = [32mcol_double()[39m,
      ..   allergie_fruits = [32mcol_double()[39m,
      ..   allergie_legumes = [32mcol_double()[39m,
      ..   regime_passe = [32mcol_double()[39m,
      ..   regime_nb_2dernann = [32mcol_double()[39m,
      ..   regime_nb_anter2dernann = [32mcol_double()[39m,
      ..   regime_type = [32mcol_double()[39m,
      ..   regime_type_libelle = [31mcol_character()[39m,
      ..   regime_duree_sem = [32mcol_double()[39m,
      ..   regime_duree_mois = [32mcol_double()[39m,
      ..   regime_duree_nsp = [32mcol_double()[39m,
      ..   poids_anndern = [32mcol_double()[39m,
      ..   poids_anndern_nsp = [32mcol_double()[39m,
      ..   poids_modif = [32mcol_double()[39m,
      ..   poids_modifalim = [32mcol_double()[39m,
      ..   poids_plusAP = [32mcol_double()[39m,
      ..   poids_medicaments = [32mcol_double()[39m,
      ..   poids_substituts = [32mcol_double()[39m,
      ..   poids_chirurgie = [32mcol_double()[39m,
      ..   poids_modifalim_laityaourt = [32mcol_double()[39m,
      ..   poids_modifalim_fromage = [32mcol_double()[39m,
      ..   poids_modifalim_mg = [32mcol_double()[39m,
      ..   poids_modifalim_fruit = [32mcol_double()[39m,
      ..   poids_modifalim_legume = [32mcol_double()[39m,
      ..   poids_modifalim_pdtfeculent = [32mcol_double()[39m,
      ..   poids_modifalim_pizza = [32mcol_double()[39m,
      ..   poids_modifalim_pain = [32mcol_double()[39m,
      ..   poids_modifalim_vrouge = [32mcol_double()[39m,
      ..   poids_modifalim_volaille = [32mcol_double()[39m,
      ..   poids_modifalim_oeuf = [32mcol_double()[39m,
      ..   poids_modifalim_gateau = [32mcol_double()[39m,
      ..   poids_modifalim_edulcorant = [32mcol_double()[39m,
      ..   poids_modifalim_pdtsalleges = [32mcol_double()[39m,
      ..   poids_modifalim_BS = [32mcol_double()[39m,
      ..   poids_modifalim_eau = [32mcol_double()[39m,
      ..   poids_modifalim_autre = [32mcol_double()[39m,
      ..   poids_modifalim_autre_libelle = [31mcol_character()[39m,
      ..   poids_perception = [32mcol_double()[39m,
      ..   poidsmax = [32mcol_double()[39m,
      ..   poidsmax_nsp = [32mcol_double()[39m,
      ..   age_poidsmax = [32mcol_double()[39m,
      ..   age_poidsmax_nsp = [32mcol_double()[39m,
      ..   poidsmin = [32mcol_double()[39m,
      ..   poidsmin_nsp = [32mcol_double()[39m,
      ..   age_poidsmin = [32mcol_double()[39m,
      ..   age_poidsmin_nsp = [32mcol_double()[39m,
      ..   nb_prise_10kg = [32mcol_double()[39m,
      ..   menopause = [32mcol_double()[39m,
      ..   enceinte = [32mcol_double()[39m,
      ..   enceinte_nbmois = [32mcol_double()[39m,
      ..   allaite = [32mcol_double()[39m,
      ..   allaite_nbsem = [33mcol_logical()[39m,
      ..   enceinte_12dermois = [32mcol_double()[39m,
      ..   fume = [32mcol_double()[39m,
      ..   nb_cigarettes_jour = [32mcol_double()[39m,
      ..   nb_cigarettes_sem = [32mcol_double()[39m,
      ..   nb_cigarettes_nsp = [32mcol_double()[39m,
      ..   nb_cigares_jour = [32mcol_double()[39m,
      ..   nb_cigares_sem = [32mcol_double()[39m,
      ..   nb_cigares_nsp = [32mcol_double()[39m,
      ..   nb_pipes_jour = [32mcol_double()[39m,
      ..   nb_pipes_sem = [32mcol_double()[39m,
      ..   nb_pipes_nsp = [32mcol_double()[39m,
      ..   fume_age_debut = [32mcol_double()[39m,
      ..   fume_age_debut_nsp = [32mcol_double()[39m,
      ..   fume_age_arret = [32mcol_double()[39m,
      ..   fume_age_arret_nsp = [32mcol_double()[39m,
      ..   bmr_kcal = [32mcol_double()[39m,
      ..   sousest0 = [32mcol_double()[39m,
      ..   surest0 = [32mcol_double()[39m,
      ..   sousest1 = [32mcol_double()[39m,
      ..   sousest3 = [32mcol_double()[39m,
      ..   sousext = [32mcol_double()[39m,
      ..   surext = [32mcol_double()[39m
      .. )
     - attr(*, "problems")=<externalptr> 


#### Imports des donn√©es depuis data.gouv.fr

Eviter cette option pour ne pas surcharger le SSP Cloud si trop de participants font des t√©l√©chargements en m√™me temps. A n'utiliser que si impossibilit√© d'utiliser le Datalab.

```r
# Lecture des fichiers CSV
description_indiv <- read_delim("https://www.data.gouv.fr/fr/datasets/r/f982ee4a-b2db-4608-ab95-bfe51dfc4897", delim=";")
habitudes_indiv <- read_delim("https://www.data.gouv.fr/fr/datasets/r/099351b9-e32e-4e38-8f23-dec21fd07c71", delim=";")
actphys_sedent <- read_delim("https://www.data.gouv.fr/fr/datasets/r/e9a34b81-2105-4d82-a023-c14947fb2b2c", delim=";")
fpq <- read_delim("https://www.data.gouv.fr/fr/datasets/r/32e79499-9897-423b-acd6-143121340f86", delim=";")
```

## Partie 1 : Analyse exploratoire des donn√©es et visualisations

Premier point de contact : Julie Sixou

Bo√Æte √† outils de ce qu'il est possible de faire avec ```dplyr``` et ```ggplot2```

Explorons la base de donn√©es INCA3 : dans cette partie, nous allons vous montrer comment produire des graphes et statistiques univari√©es et bivari√©es.

Le dictionnaire des variables et des modalit√©s peut se trouver ici : https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf
<br>

### Imports


```R
# Import des librairies

library(ggplot2)
library(ggcorrplot)
library(sf)
```

    Linking to GEOS 3.10.2, GDAL 3.4.1, PROJ 8.2.1; sf_use_s2() is TRUE
    



```R
# Option d'affichage
options(dplyr.width = Inf)
options(repr.plot.width=20, repr.plot.height=10)
```

### 1. Statistiques univari√©es avec la table _description_indiv_

Quelques exemples de ce qu'il est possible de faire avec ```ggplot2``` :


```R
# Histogramme des IMC

ggplot(data=description_indiv,aes(x=imc))+
    geom_histogram(binwidth=1,color="grey",fill="lightblue")
```

    Warning message:
    ‚Äú[1m[22mRemoved 14 rows containing non-finite values (`stat_bin()`).‚Äù



    
![png](output_26_1.png)
    



```R
# Histogramme des niveaux de dipl√¥me

ggplot(data=description_indiv,aes(x=diplome_interv))+ 
    geom_histogram(binwidth=1,color="black",fill="darkred")+
    labs(title="Histogramme des niveaux de dipl√¥me",  # cette fois on rajoute des l√©gendes
    x="Code du niveau de dipl√¥me",
    y="Nombre d'individus")
```

    Warning message:
    ‚Äú[1m[22mRemoved 1 rows containing non-finite values (`stat_bin()`).‚Äù



    
![png](output_27_1.png)
    


Recodons la variable des niveaux de dipl√¥me pour mieux comprendre le graphe :


```R
# Recodage des niveaux de dipl√¥me

description_indiv <- description_indiv %>% mutate(categorie_diplome=case_when(diplome_interv==1 ~ "Aucun dipl√¥me, n'a jamais √©t√© scolaris√©",
                                                                              diplome_interv==2 ~ "Aucun dipl√¥me, scolarit√© s'est arr√™t√©e √† l'√©cole primaire",
                                                                              diplome_interv==3 ~ "Aucun dipl√¥me, scolarit√© s'est arr√™t√©e au coll√®ge",
                                                                              diplome_interv==4 ~ "Aucun dipl√¥me, scolarit√© s'est arr√™t√©e au del√† du coll√®ge",
                                                                              diplome_interv==5 ~ "Aucun dipl√¥me, sans pr√©cision",
                                                                              diplome_interv==6 ~ "CEP",
                                                                              diplome_interv==7 ~ "CAP, BEP, BEPC, brevet √©l√©mentaire, brevet de compagnon",
                                                                              diplome_interv==8 ~ "Baccalaur√©at technologique ou professionnel,\nBrevet professionnel ou de technicien,\nBEA, BEC, BEI, BEH, capacit√© en droit",
                                                                              diplome_interv==9 ~ "Baccalaur√©at g√©n√©ral",
                                                                              diplome_interv==10 ~ "Dipl√¥me de 1er cycle universitaire (Bac +3, licence),\nBTS, DUT, DEST, DEUG, dipl√¥me des professions\nsociales ou de la sant√©, d'infirmier",
                                                                              diplome_interv==11 ~ "Dipl√¥me de 2√®me cycle universitaire (Bac+4, Bac+5),\nMaster, Ma√Ætrise, dipl√¥me d'ing√©nieur,\nd'une grande √©cole",
                                                                              diplome_interv==12 ~ "Dipl√¥me de 3√®me cycle universitaire (>Bac+5, doctorat),\ndipl√¥me de v√©t√©rinaire, m√©decin, pharmacien",
                                                                              diplome_interv==13 ~ "Refus",
                                                                              diplome_interv==14 ~ "Ne sait pas"))
```


```R
# Tableau des fr√©quences de chaque cat√©gorie de diplome
counts_diplome <- description_indiv %>% group_by(categorie_diplome) %>% summarise(n=n())

# Graphique en barres horizontales
ggplot(data=counts_diplome,aes(x=categorie_diplome,y=n))+
    geom_histogram(stat="identity")+
coord_flip()+
labs(title="Histogramme des niveaux de dipl√¥me",
     x="Libelle du niveau de dipl√¥me",
     y="Nombre d'individus")
```

    Warning message in geom_histogram(stat = "identity"):
    ‚Äú[1m[22mIgnoring unknown parameters: `binwidth`, `bins`, and `pad`‚Äù



    
![png](output_30_1.png)
    



```R
# Recodage de la variable de type d'agglom√©ration

description_indiv <- description_indiv %>% mutate(categorie_agglo = case_when(agglo_5cl==1 ~ "Rural",
                                                                             agglo_5cl==2 ~ "2000 - 19 999 hab",
                                                                             agglo_5cl==3 ~ "20 000 - 99 999 hab",
                                                                             agglo_5cl==4 ~ "+ 100 000 hab",
                                                                             agglo_5cl==5 ~ "Paris"))
```


```R
counts_agglo <- description_indiv %>% group_by(categorie_agglo) %>% summarise(n=n())

# G√©n√©rer le graphique en barres horizontales
ggplot(data=counts_agglo,aes(x=categorie_agglo,y=n))+
    geom_histogram(stat="identity")+
    coord_flip()+ 
    labs(title="Histogramme des types d'agglom√©ration",
          x="Type d'agglom√©ration",
          y="Nombre d'individus")
```

    Warning message in geom_histogram(stat = "identity"):
    ‚Äú[1m[22mIgnoring unknown parameters: `binwidth`, `bins`, and `pad`‚Äù



    
![png](output_32_1.png)
    


A vous de jouer, faites la m√™me chose pour les tranches de revenu : histogramme de la variable **RUC_4cl** qui donne le revenu mensuel total du foyer par unit√© de consommation (UC) en 4 classes. Les modalit√©s de la variable sont les suivantes :


```R
# Niveau de vie

description_indiv <- description_indiv %>% mutate(categorie_ruc=case_when(RUC_4cl==1 ~ "<900 ‚Ç¨/mois/UC",
                                                                         RUC_4cl==2 ~ "[900-1 340[ ‚Ç¨/mois/UC",
                                                                         RUC_4cl==3 ~ "[1 340-1 850[ ‚Ç¨/mois/U",
                                                                         RUC_4cl==4 ~ ">=1 850 ‚Ç¨/mois/UC"))

```


```R
# TODO
counts_ruc <- description_indiv %>% group_by(categorie_ruc) %>% summarise(n=n())

# G√©n√©rer le graphique en barres horizontales
ggplot(data=counts_ruc,aes(x=categorie_ruc,y=n))+
    geom_histogram(stat="identity")+
    coord_flip()+ 
    labs(title="Histogramme des niveaux de revenus",
          x="Tranches de revenu",
          y="Nombre d'individus")
```

    Warning message in geom_histogram(stat = "identity"):
    ‚Äú[1m[22mIgnoring unknown parameters: `binwidth`, `bins`, and `pad`‚Äù



    
![png](output_35_1.png)
    


### 2. Statistiques bivari√©es avec les tables _description_indiv_ et _habitudes_indiv_

Quelques exemples de ce qu'il est possible de faire avec ```ggplot2``` :


```R
# Imc moyen par niveau de dipl√¥me

imc_par_diplome <- description_indiv %>% group_by(categorie_diplome) %>% summarise(imc_moyen=mean(imc,na.rm=TRUE))

ggplot(data=imc_par_diplome,aes(x=categorie_diplome,y=imc_moyen))+
geom_histogram(stat="identity")+
coord_flip()+
labs(title="IMC moyen par niveau de diplome",
     x="Cat√©gorie de diplome",
     y="IMC moyen")
```

    Warning message in geom_histogram(stat = "identity"):
    ‚Äú[1m[22mIgnoring unknown parameters: `binwidth`, `bins`, and `pad`‚Äù



    
![png](output_38_1.png)
    



```R
# Autoproduction par type d'agglom√©ration
description_x_habitudes <- description_indiv %>% left_join(habitudes_indiv,by="NOIND")
```


```R
autoprod_par_agglo <- description_x_habitudes %>% group_by(categorie_agglo) %>% summarise(part_autoprod=mean(autoproduction,na.rm=TRUE))
ggplot(data=autoprod_par_agglo,aes(x=categorie_agglo,y=part_autoprod))+
geom_histogram(stat="identity")+
labs(title="Part d'autoproduction par type d'agglom√©ration",
     x="Type d'agglom√©ration",
     y="Part d'autoproduction")
```

    Warning message in geom_histogram(stat = "identity"):
    ‚Äú[1m[22mIgnoring unknown parameters: `binwidth`, `bins`, and `pad`‚Äù



    
![png](output_40_1.png)
    


A vous de jouer, repr√©sentez le croisement entre le score d'ins√©curit√© d'alimentaire (**IA_score**, on peut en faire la moyenne) et les tranches de revenu (par exemple, **RUC_4cl** qu'on a recod√©e pr√©c√©demment, ou **revenu** qui donne le revenu disponible cod√© en plus de classes.)

Le dictionnaire des variables et des modalit√©s peut se trouver ici : https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf


```R
# Score d'IA par tranche de revenu

# TODO
# Score d'IA par tranche de revenu

scoreIA_par_tr_rev <- description_x_habitudes %>% group_by(categorie_ruc) %>% summarise(IA_score_moy=mean(IA_score,na.rm=TRUE))
ggplot(data=scoreIA_par_tr_rev,aes(x=categorie_ruc,y=IA_score_moy))+
geom_histogram(stat="identity")+
coord_flip()+
labs(title="Score IA moyen par tranche de revenu",
     x="Tranche de Revenu",
     y="score d'ins√©curit√© alimentaire")
```

    Warning message in geom_histogram(stat = "identity"):
    ‚Äú[1m[22mIgnoring unknown parameters: `binwidth`, `bins`, and `pad`‚Äù



    
![png](output_42_1.png)
    


Finalement, on se rend compte que la base est tr√®s riche et contient beaucoup de variables : beaucoup d'entre elles sont quantitatives, et on peut s'amuser √† repr√©senter leurs relations de corr√©lations en m√™me temps dans une matrice de corr√©lation.


```R
df_num <- description_x_habitudes %>% select(where(is.numeric))

df_num <- df_num %>% select(c("revenu","IA_score","imc","regime_vegetarien","poidsmax","fume","source_famille","jardin_potager","autoconsommation","consommation_bio"))

matrice_correlation <- model.matrix(~0+., data=df_num) %>% 
  cor(use="pairwise.complete.obs")
```

matrice_correlation %>%   ggcorrplot(show.diag=FALSE, type="lower", lab=TRUE, lab_size=7)

A vous d'ajouter les variables qui vous int√©ressent et √† multiplier les visualisations !
Les plus beaux graphes seront partag√©s √† l'issue du funathon.


```R
# TODO
#install.packages("DataExplorer")
library("DataExplorer")
plot_correlation(df_num, cor_args = list("use" = "pairwise.complete.obs"),title = "YEZ",theme_config = list(legend.position = "bottom", axis.text.x = element_text(size=20),
                                                                                                            axis.text.y = element_text(size=20))) 

```


    
![png](output_47_0.png)
    



```R

runExample("01_hello", host="0.0.0.0", port=5749)


```

    
    Listening on http://0.0.0.0:5749
    



```R
### 3. Cartographie
```

Pour la cartographie, on a besoin de fonds de carte. Ce sont des bases d'objets vectoriels. Par exemple, pour une carte de France par r√©gion, on aura une ligne par r√©gion avec un attribut g√©ographique renseignant les coordonn√©es du vecteur (ou polygone). Le package **cartiflette** nous permet de les t√©l√©charger directement et facilement.


```R
url <- "https://minio.lab.sspcloud.fr/projet-cartiflette/diffusion/shapefiles-test1/year%3D2022/administrative_level%3DREGION/crs%3D4326/FRANCE_ENTIERE%3Dmetropole/vectorfile_format%3D%27geojson%27/provider%3D%27IGN%27/source%3D%27EXPRESS-COG-CARTO-TERRITOIRE%27/raw.geojson"
```


```R
region <- sf::st_read(url)
```


```R
# Passons le fonds de carte dans le syst√®me de coordonn√©es de r√©f√©rence utilis√© pour la FRance, Lambert 93 (code : 2154) au lieu de WGS 84
region <- region %>% st_transform(2154)
```


```R
# Repr√©sentons les contours de notre fond de carte
plot(st_geometry(region))
```


```R
region$NOM_M
region <- region %>% mutate(NOM_M=ifelse(NOM_M=="CORSE", "PROVENCE-ALPES-COTE D'AZUR", NOM_M))
```

On va s'int√©resser aux fr√©quences de consommation de certains aliments, pr√©sentes dans la table fpq.


```R
description_x_fpq = left_join(description_indiv, fpq, by="NOIND")
```


```R
# Recodage de la variable r√©gion pour avoir les m√™mes noms que dans notre fond de carte

description_x_fpq <- description_x_fpq %>% mutate(region_recode=case_when(region_adm_12cl==1 ~ "ILE-DE-FRANCE",
                                                                         region_adm_12cl==2 ~ "NORMANDIE",
                                                                         region_adm_12cl==3 ~ "CENTRE-VAL DE LOIRE",
                                                                         region_adm_12cl==4 ~ "PAYS DE LA LOIRE",
                                                                         region_adm_12cl==5 ~ "BRETAGNE",
                                                                         region_adm_12cl==6 ~ "HAUTS-DE-FRANCE",
                                                                         region_adm_12cl==7 ~ "GRAND EST",
                                                                         region_adm_12cl==8 ~ "BOURGOGNE-FRANCHE-COMTE",
                                                                         region_adm_12cl==9 ~ "AUVERGNE-RHONE-ALPES",
                                                                         region_adm_12cl==10 ~ "PROVENCE-ALPES-COTE D'AZUR",
                                                                         region_adm_12cl==11 ~ "OCCITANIE",
                                                                         region_adm_12cl==12 ~ "NOUVELLE-AQUITAINE",))
```


```R
# Variable √† repr√©senter g√©ographiquement : nombre de bi√®re consomm√©es par mois. 

biere_par_region <- description_x_fpq %>% group_by(region_recode) %>% summarise(freq_conso_biere_moyenne=mean(BA_biere_freq_M,na.rm=TRUE))
biere_par_region
```


```R
# On cr√©e un petit tableau avec nos r√©gions et leurs attributs g√©ographiques, 
# et surtout la variable qu'on vient de calculer (c'est-√†-dire le nombre de bi√®res consomm√©es par mois par r√©gion en moyenne)

region_inca <- left_join(region,biere_par_region,by=c("NOM_M"="region_recode"))
```


```R
region_inca$freq_conso_biere_moyenne
```


```R
ggplot(data=region_inca) +
geom_sf(aes(fill=freq_conso_biere_moyenne)) +
scale_fill_continuous(low="yellow", high="Red", name="Nombre de bi√®res consomm√©es par mois en moyenne") +
labs(title="Nombre de bi√®res consomm√©es par mois en moyenne par r√©gion")
```

Maintenant, cr√©ez votre propre carte ! Vous pouvez regarder directement dans le dictionnaire des variables, ou bien vous aider des libell√©s.
Les fr√©quences en nombre de jours par mois finissent par _freq_M, et les indicatrices de consommation finissent par _ON (ces derni√®res valent 1 si le produit est consomm√© et 0 sinon). 

Par exemple, on peut choisir parmi les variables dans : ```colnames(fpq)```


```R
# TODO
```

## Partie 2 : Clustering d'individus

Premier point de contact : Antoine Palazzolo

Lorsque l'on pense au Machine Learning, les premiers exemples qui viennent en t√™te sont souvent des probl√®mes de r√©gression ou bien de classification.
Ces cas d'usage font partie d'une branche du ML appel√©e _apprentissage supervis√©_, qui requiert notamment d'avoir des donn√©es labellis√©es permettant aux diverses m√©thodes utilis√©es de comprendre la relation entre un ensemble de variables explicatives et une variable √† pr√©dire.

_L'apprentissage non supervis√©_ est une autre branche du ML qui ne consiste cette fois plus √† pr√©dire une variable donn√©e √† partir de donn√©es labellis√©es.
Au coeur de l'apprentissage non supervis√© on trouve notamment le __clustering__.
Cette fois-ci, le but est de cr√©er √† partir d'une population donn√©e un ensemble de clusters (ou paquets) d'individus regroup√©s par similarit√©, en utilisant de fa√ßon automatiques les caract√©ristiques les plus discriminantes de notre population. Ce sera peut-√™tre plus clair avec quelques exemples et applications :
- Une enseigne de retail poss√®de une centaine de magasins en France et souhaite regrouper ces derniers en une poign√©e de groupes qu'elle pourra approvisionner de la m√™me fa√ßon. Chaque groupe devra regrouper des magasins ayant des performances similaires et une client√®le proche. C'est un probl√®me de clustering.
- A partir d'une base de donn√©es regroupant les th√®mes de pr√©dilection de centaines de journalistes (ou bien leurs r√©f√©rences), on souhaite regrouper ces m√™mes journalistes en quelques cat√©gories au sein desquelles chaque individu aura une orientation politique proche de celles des autres.
- En fonction des caract√©ristiques physiques d'esp√®ces animales ou v√©g√©tales, on souhaite regrouper ces esp√®ces en un plus petit nombre de groupes.



Il existe plusieurs m√©thodes pour faire du clustering, les deux plus connues √©tant :
- Les [K-Moyennes](https://fr.wikipedia.org/wiki/K-moyennes) (ou K-Means), m√©thode la plus connue, bas√©e sur l'utilisation de centro√Ødes it√©r√©s
- Le [Clustering Ascendant Hi√©rarchique](https://fr.wikipedia.org/wiki/Regroupement_hi%C3%A9rarchique) (CAH), bas√© sur des regroupements en groupes de plus en plus grands, donnant par exemple lieu √† des visualisations sous forme de dendrogrammes (ressemblant aux arbres phylog√©n√©tiques de vos cours de SVT au lyc√©e)

Nous allons mettre en pratique ces deux m√©thodes dans ce sujet.

Une fois nos clusterings effectu√©s, l'un des enjeux est ensuite aussi de pouvoir interpr√©ter ces derniers :
- Quelles sont les caract√©ristiques les plus discriminantes dans la constitution des groupes ?
- Les clusters g√©n√©r√©s font-ils bien sens ? Que peut-on dire de ces groupes ?
- Quelles m√©thodes de visualisation sont les plus adapt√©es ?

Pour r√©pondre √† ces questions, un des outils principaux que nous pouvons utiliser est l'[Analyse en Composantes Principales](https://fr.wikipedia.org/wiki/Analyse_en_composantes_principales) (ACP), qui √† partir de l'ensemble initial des colonnes en cr√©e un ensemble de taille r√©duite qui maximise la discrimination des donn√©es les unes par rapport aux autres via ces nouvelles colonnes.
En r√©duisant la dimension √† moins de 3, on peut ainsi repr√©senter graphiquement les donn√©es de fa√ßon plus claire.

### 1. Preprocessing des donn√©es

Pour cette √©tude nous allons commencer par la table des habitudes individuelles.
Cette table contient les donn√©es des questionnaires auto-administr√©s relatifs aux volets ¬´ Habitudes alimentaires ¬ª et ¬´ Origine des aliments ¬ª.

Elle regroupe les informations suivantes : lieux et occasions de consommation, consommations hors-foyer et entre les repas, pr√©f√©rences alimentaires, pr√©sence de sel/beurre/sauce sur la table au moment des repas, lecture des √©tiquettes, sources d‚Äôinformations en alimentation, consommation de denr√©es animales crues et des cro√ªtes de fromage, pr√©paration des fruits et l√©gumes crus, sp√©cificit√©s de l‚Äôalimentation des enfants de 0 √† 35 mois (ex : allaitement (exclusif ou partiel), type de laits consomm√©s, diversification alimentaire, mat√©riaux des biberons et des t√©tines, pr√©paration, stockage et conservation des biberons de lait, mode de chauffage des laits et contenants utilis√©s), autoconsommation et utilisation de produits phytosanitaires au potager, consommation d‚Äôaliments issus de l‚Äôagriculture biologique et cuisson des aliments au barbecue.

Une fois le sujet termin√©, vous pourrez si vous le souhaitez reproduire cette partie avec d'autres des tables √† disposition.


```R
# Dimensions de habitudes_indiv
n_rows <- nrow(habitudes_indiv)
n_cols <- ncol(habitudes_indiv)

# Affichage des dimensions
print(paste("Nombre de lignes :", n_rows))
print(paste("Nombre de colonnes :", n_cols))
```


```R
head(habitudes_indiv, 3)
```

#### Etape 1 : Analyse exploratoire & s√©lection de variables

Regardons d√©j√† √† quoi ressemblent nos donn√©es en pratique. En utilisant dplyr, pouvez-vous dire :
- Combien y a-t-il d'individus et de variables ?
- Combien de variables pr√©sentent des valeurs vides ? En quelle proportion ?
- Y a-t-il des variables qui ont la m√™me valeur pour tous les individus ? Seront-elles utiles pour la discrimination des observations dans le clustering ?
- Y a-t-il des variables qui n'ont pas de sens pour la caract√©risation d'un groupe ? Cela comprend par exemple les identifiants.
- Quels sont les types des variables ? Combien de variables non-num√©riques ? En pratique nous allons ici nous focaliser uniquement sur les donn√©es num√©riques de la table.


```R
# A vous de jouer !

# TODO
```

A partir des analyses que vous venez de r√©aliser, vous devriez avoir une meilleure id√©e de quoi garder dans la table pour appliquer les m√©thodes de clustering. Cr√©ez donc ```habitudes_indiv_clustering_1``` √† partir de ```habitudes_indiv``` en retirant toutes les colonnes g√™nantes ou inutiles :

<details>
<summary> Si besoin, d√©rouler pour r√©v√©ler les indications plus d√©taill√©es :</summary>
<br>

Il vous faudra donc, a minima :
- Retirer les colonnes d'identifiants
- Retirer les colonnes vides
- Conserver uniquement les colonnes num√©riques

Pour aller plus loin, retirez les colonnes √† moins de 2 valeurs distinctes.

</details>



```R
habitudes_indiv_clustering_1 <- data.frame() # TODO
```


```R
# Dimensions de habitudes_indiv
n_cols <- ncol(habitudes_indiv_clustering_1)

# Affichage des dimensions
print(paste("Nombre de colonnes :", n_cols))
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
# S√©lectionner les caract√©ristiques pour le clustering
habitudes_indiv_clustering_1 <- habitudes_indiv %>%
  select(-c(POPULATION, NOIND, periode_reference)) %>%  # Identifiants
  select_if(function(col) any(!is.na(col))) %>%  # Colonnes vides
  select_if(is.numeric) %>%  # Colonnes num√©riques √† garder
  select_if(function(col) length(unique(col)) > 1)  # On retire les colonnes avec moins de 2 valeurs distinctes
```

</details>


#### Etape 2 : Imputation

Comme vous l'avez peut-√™tre vu, si l'on cherche √† retirer toutes les lignes ou colonnes avec au moins une valeur manquante, il ne reste plus grand-chose √† la table...
Nous allons donc les garder, d'autant plus que cela ne les emp√™che pas de contenir de l'information importante.

Dans ce cas comment traiter les NaNs ?
Il existe une m√©thode pour les remplacer par une valeur num√©rique, il s'agit de l'__[imputation](https://fr.wikipedia.org/wiki/Imputation_(statistique))__.

Plusieurs m√©thodes d'imputation existent : remplacer les valeurs manquantes par la moyenne de la colonne, par une valeur issue de r√©gression lin√©aire, de r√©gression stochastique, etc.

Dans notre cas particulier, la plupart des variables sont binaires, des r√©ponses Oui/Non √† une question.
Une m√©thode que nous pouvons donc utiliser (mais d'autres marcheraient tr√®s bien aussi) est l'imputation par la valeur non vide la plus fr√©quente de la colonne.

En termes d'interpr√©tation, cela revient √† simplifier le probl√®me en consid√©rant que les non-r√©pondants auraient r√©pondu la m√™me chose que la majorit√© des r√©pondants, quitte √† ce que cela m√®ne √† de possibles erreurs.
Par exemple, les r√©pondants "Homme" ont peu de chances de r√©pondre "Oui" √† l'allaitement, mais c'est une solution qui fonctionne tout de m√™me en g√©n√©ral tr√®s bien.

<br>

A pr√©sent, appliquez cette strat√©gie d'imputation sur la table ```habitudes_indiv_clustering_1``` pour donner naissance √† ```habitudes_indiv_clustering_2```.


```R
habitudes_indiv_clustering_2 <- data.frame() # TODO
```


```R
# Dimensions de habitudes_indiv
n_cols <- ncol(habitudes_indiv_clustering_2)

# Affichage des dimensions
print(paste("Nombre de colonnes :", n_cols))
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
Mode <- function(x) {
  non_missing_values <- x[!is.na(x)]
  ux <- unique(non_missing_values)
  ux[which.max(tabulate(match(non_missing_values, ux)))]
}

# Remplacer les valeurs manquantes (NaN) par le mode
habitudes_indiv_clustering_2 <- habitudes_indiv_clustering_1 %>%
  mutate_all(~ifelse(is.na(.), Mode(.), .)) %>%
select_if(function(col) length(unique(col)) > 1)  # On re-retire les colonnes avec moins de 2 valeurs distinctes pour s'√©viter des erreurs par la suite
```

</details>


#### Etape 3 : Normalisation des colonnes

Pour la plupart des m√©thodes que nous allons utiliser, nous ne souhaitons pas n√©cessairement donner plus d'importance √† une colonne qu'√† une autre.
Or pour plusieurs des fonctions que nous allons manipuler, le poids affect√© √† une colonne peut d√©pendre de sa moyenne ou de sa variance.

Ici, les questions √©tant pour la plupart binaires, nous ne voulons pas qu'une question avec davantage de r√©ponses positives ait une importance plus grande qu'une autre.
Nous devons donc renormaliser les colonnes pour corriger ce probl√®me.

A vous de jouer : renormalisez l'ensemble des colonnes pour amener leur moyenne √† 0 et leur variance √† 1. Vous stockerez le r√©sultat dans le tableau ```habitudes_indiv_clustering_3```.


```R
habitudes_indiv_clustering_3 <- data.frame() # TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
# Normalisation des colonnes
habitudes_indiv_clustering_3 <- scale(habitudes_indiv_clustering_2)
```

</details>


#### Etape 4 : Gestion des outliers

Dans ce type de questionnaire il n'est pas rare de trouver des observations aberrantes, par exemple en raison d'individus r√©pondant de fa√ßon absurde aux questions.
De fa√ßon g√©n√©rale, si la base de donn√©es est suffisamment grande et que l'on ne s'int√©resse pas n√©cessairement √† chaque individu, une bonne pratique peut √™tre de retirer les outliers de notre base.
Cela permet en effet de limiter les risques d'avoir des clusters √† un seul individu ne repr√©sentant rien d'int√©ressant ou d'avoir des visualisations d√©form√©es par une observation tr√®s loin par rapport aux autres.

A vous de jouer : retirez les outliers de la table ```habitudes_indiv_clustering_3```, disons 3% des observations, et stockez le r√©sultat dans la table ```habitudes_indiv_clustering_4```.

Vous pouvez importer et utiliser le package ```isotree```, notamment les m√©thodes ```isolation.forest()``` et ```predict()```.


```R
habitudes_indiv_clustering_4 <- data.frame() # TODO
```


```R
# Dimensions de habitudes_indiv
n_rows <- nrow(habitudes_indiv_clustering_4)

# Affichage des dimensions
print(paste("Nombre de lignes restantes :", n_rows))
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
library(isotree)

outlier_detector <- isolation.forest(habitudes_indiv_clustering_3)
is_outlier_scores <- predict(outlier_detector, habitudes_indiv_clustering_3)
sorted_oulier_scores <- order(is_outlier_scores)

nb_observations_to_keep <- round(0.97 * nrow(habitudes_indiv_clustering_3))
habitudes_indiv_clustering_4 <- habitudes_indiv_clustering_3[sorted_oulier_scores[1:nb_observations_to_keep], ] %>%
select_if(function(col) length(unique(col)) > 1)  # On re-retire les colonnes avec moins de 2 valeurs distinctes pour s'√©viter des erreurs par la suite
```

</details>

Si vous le souhaitez, vous pourrez dans un second temps reproduire la suite sans retirer les outliers pour comparer les r√©sultats obtenus.

<br>

Vous avez √† pr√©sent termin√© le preprocessing de la table pour la partie Clustering.
Libre √† vous de rajouter des op√©rations suppl√©mentaires si vous en voyez le besoin.
Sinon nous pouvons rentrer dans le vif du sujet.

Pour simplifier les notations, ex√©cutez la cellule ci-dessous :


```R
habitudes_indiv_clustering <- as.data.frame(habitudes_indiv_clustering_4) %>%
select_if(function(col) length(unique(col)) > 1)  # On re-retire les colonnes avec moins de 2 valeurs distinctes pour s'√©viter des erreurs par la suite

dim(habitudes_indiv_clustering)
```

### 2. Le clustering en lui-m√™me

Dans cette partie, nous allons mettre en pratique les 2 m√©thodes de clustering les plus classiques :
- Les K-Moyennes (ou K-Means)
- Le Clustering Ascendant Hi√©rarchique (CAH)

#### K-Moyennes

Dans ce sujet, nous ne revenons pas sur la th√©orie derri√®re l'algorithme du K-Means.
Donc si vous √™tes int√©ress√©s pour savoir ce qui se passe derri√®re l'utilisation du package en bo√Æte noire, la documentation sur cette th√©matique est largement disponible sur Internet.

##### Choisir le nombre de clusters

Une particularit√© des K-moyennes est qu'il faut choisir en amont de l'application de l'algorithme le nombre de clusters (ou de centro√Ødes) ```k```, a priori sans savoir quel serait le nombre optimal.
Il existe plusieurs m√©thodes pour faire ce choix :
- S'il existe des contraintes m√©tier ou des interpr√©tations relatives au "monde r√©el" imposant une valeur de ```k```
- En utilisant la m√©thode dite du __coude__, qui est la fa√ßon la plus simple d'avoir une id√©e de ```k``` √† utiliser.
    + Le principe est de lancer le K-means avec plusieurs valeurs de ```k```, repr√©senter une mesure de la distance moyenne intra-clusters en fonction de ```k``` et trouver le premier point d'inflexion
    + En revanche, le ```k``` renvoy√© n'est pas toujours stable et parfois peu pertinent.
- En utilisant la m√©thode dite de __silhouette__, m√©thode a priori plus fine mais un peu plus complexe que celle du coude
    + Le score √† maximiser par rapport √† ```k``` est cette fois la moyenne d'une mesure de la similitude d‚Äôune observation √† l‚Äôint√©rieur d‚Äôun groupe par rapport √† d‚Äôautres groupes pour chaque point

A titre d'exemple, utilisez la m√©thode du coude pour trouver le nombre optimal de clusters pour les donn√©es de ```habitudes_indiv_clustering```. On cherchera un ```k``` compris entre 1 et 10.

Vous pouvez importer et utiliser la fonction ```fviz_nbclust()``` du package ```factoextra```.


```R
# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
library(factoextra)
library(cluster)

# M√©thode du coude
elbow_method <- fviz_nbclust(habitudes_indiv_clustering, kmeans, method = "wss", k.max = 10)
elbow_method
```

</details>

A pr√©sent faites la m√™me chose mais avec la m√©thode de Silhouette :


```R
# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
# M√©thode de Silhouette
silhouette_method <- fviz_nbclust(habitudes_indiv_clustering, kmeans, method = "silhouette", k.max = 10)
silhouette_method
```

</details>

Quel est le ```k``` obtenu ? Cette valeur reste-t-elle la m√™me si vous lancez la m√©thode plusieurs fois ?

S'il n'y a pas de point d'inflexion (ou coude) bien d√©fini sur le premier graphique produit, la valeur peut souvent varier. Pour la suite du sujet, nous conserverons une valeur fixe, que vous pourrez modifier par la suite si vous le souhaitez. Ex√©cutez la ligne ci-dessous :


```R
k_kmeans <- 3
```

##### Le clustering en lui-m√™me

Une fois les donn√©es pr√©process√©es et le ```k``` d√©termin√©, clusteriser les donn√©es n'est plus tr√®s difficile.

Cr√©ez le vecteur ```clusters_kmeans``` des clusters obtenus par la m√©thode des K-moyennes :


```R
# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
k_moyennes <- kmeans(habitudes_indiv_clustering, centers = k_kmeans, nstart = 20)

# Assignation des clusters
clusters_kmeans <- k_moyennes$cluster
```

</details>

F√©licitations, vous avez d√©sormais vos clusters !
Pouvez-vous dire quelle est la taille de chacun ? Ces valeurs sont-elles proches les unes des autres ? Pouvez-vous d√©j√† interpr√©ter vos r√©sultats ?


```R
# TODO
```

On a certes obtenu nos clusters, mais tout cela n'est pas encore tr√®s visuel...

Mais pas de panique, plus que quelques cellules √† attendre pour passer √† la visualisation par ACP !

#### Clustering Ascendant Hi√©rarchique

Avant de passer √† la visualisation, nous allons nous attarder sur une autre m√©thode de clustering, √† peu pr√®s √©quivalente aux K-moyennes en termes de performances, mais dont les r√©sultats sont beaucoup plus visuels : le [CAH](https://www.xlstat.com/fr/solutions/fonctionnalites/classification-ascendante-hierarchique-cah). Comment est-ce que √ßa marche ?

- On commence par calculer la dissimilarit√© entre nos N individus, ie leur distance deux √† deux dans l'espace de nos variables
- Puis on regroupe les deux individus dont le regroupement minimise un crit√®re d'agr√©gation donn√©, cr√©ant ainsi une classe comprenant ces deux individus.
- On calcule ensuite la dissimilarit√© entre cette classe et les N-2 autres individus en utilisant le crit√®re d'agr√©gation.
- Puis on regroupe les deux individus ou classes d'individus dont le regroupement minimise le crit√®re d'agr√©gation.
- On continue ainsi jusqu'√† ce que tous les individus soient regroup√©s.

Ces regroupements successifs produisent un arbre binaire de classification (_dendrogramme_), dont la racine correspond √† la classe regroupant l'ensemble des individus.
Ce dendrogramme repr√©sente une hi√©rarchie de partitions.
On peut alors choisir une partition en tronquant l'arbre √† un niveau donn√©, le niveau d√©pendant soit des contraintes de l'utilisateur, soit de crit√®res plus objectifs.

<br>

Dans ce sujet, nous allons nous limiter √† la m√©thode d'agr√©gation la plus standard, dite de __Ward__.
Cr√©ez les regroupements successifs mentionn√©s plus haut.
Le r√©sultat tient en une ligne.


```R
regroupements <- '' # TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
regroupements <- hclust(dist(habitudes_indiv_clustering), method = 'ward.D')
```

</details>

Maintenant les regroupements effectu√©s, vous pouvez dessiner le dendrogramme les repr√©sentant.
Pour des contraintes de lisibilit√©, nous vous recommandons si vous y arrivez de limiter l'affichage de l'arbre √† une profondeur de 6.

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
plot(regroupements, hang = -1, labels = FALSE)

```

</details>

Si tout s'est bien pass√© jusqu'ici, vous devriez avoir un magnifique dendrogramme sous les yeux !

Cependant une question demeure : jusque-l√† la probl√©matique du nombre de clusters √† utiliser ne s'est toujours pas pos√©e, comment allons-nous choisir maintenant ?
Encore une fois, des contraintes du monde r√©el peuvent venir diriger le choix.
Si ce n'est pas le cas, on peut faire par rapport √† l'allure du dendrogramme, en choisissant une coupe horizontale de l'arbre coh√©rente.
Cette coupe d√©termine alors les clusters finaux.

En utilisant la fonction ```cutree()```, r√©alisez cette coupe du dendrogramme au niveau ```k_cah = 3``` pour cr√©er le vecteur ```clusters_cah``` des clusters obtenus par CAH. Une fois les clusters g√©n√©r√©s, que pouvez-vous en dire ? Est-ce coh√©rent avec votre dendrogramme ?

Une fois le reste du sujet effectu√©, vous pourrez √©galement reprendre cette partie avec ```k_cah = 4```.


```R
k_cah <- 3  # Nombre de clusters souhait√©

# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
clusters_cah <- cutree(regroupements, k = k_cah)

```

</details>

Maintenant les clusters obtenus par deux m√©thodes diff√©rentes, il est temps de passer √† la visualisation !

### 3. Visualisations et interpr√©tations

#### R√©aliser l'ACP

La m√©thode la plus simple pour visualiser nos clusters serait de repr√©senter chaque individu dans l'espace √† N dimensions des variables de la table, et colorier chaque individu en fonction de son cluster.
On pourrait alors bien diff√©rencier les variables les plus discrimantes et les diff√©rents groupes.
Un seul probl√®me ici : d√®s que N > 3, nous avons du mal √† repr√©senter le r√©sultat de fa√ßon intelligible...

C'est l√† qu'intervient __l'Analyse en Composantes Principales__ ([ACP](https://www.xlstat.com/fr/solutions/fonctionnalites/analyse-en-composantes-principales-acp)), qui permet de projeter notre espace √† haute dimension dans un espace de dimension plus petite.
La contrainte majeure de la projection est de pouvoir conserver le maximum d'information (mesur√©e par la variance totale de l'ensemble de donn√©es) dans notre nombre r√©duit de dimensions, appel√©es composantes principales.
En se limitant √† 2 ou 3 dimensions, on peut ainsi se repr√©senter visuellement les relations entre les observations avec une perte de fiabilit√© minimale.

Dans notre situation, on peut esp√©rer que les clusters d√©termin√©s dans notre espace √† N dimensions se diff√©rencient bien sur notre projection par ACP, et que la composition des composantes principales en fonction des variables initiales permette d'interpr√©ter les clusters obtenus. Nous allons donc tester cette hypoth√®se !

<br>

Nous allons commencer par le calcul des 3 composantes principales. Cr√©ez :
- Un dataframe ```projection_individus``` correspondant √† la projection des individus de ```habitudes_indiv_clustering``` dans l'espace des composantes principales. Ce dataframe aura donc 3 colonnes, que l'on pourra nommer si ce n'est pas automatiquement le cas [PC1, PC2, PC3].
- Un dataframe ```composantes_principales``` avec les m√™mes colonnes que ```projection_individus```, mais o√π la ligne i correspond √† la contribution relative de la variable i √† chacune des composantes de l'ACP.

Vous pourrez vous servir de la fonction ```prcomp()``` du package de base R.


```R
nb_composantes_principales <- 3

# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
nb_composantes_principales <- 3

acp <- prcomp(habitudes_indiv_clustering, retx = TRUE, rank. = nb_composantes_principales)
projection_individus <- data.frame(acp$x)
composantes_principales  <- data.frame(acp$rotation)
```

</details>

Maintenant l'ACP termin√©e, nous allons t√¢cher d'interpr√©ter les composantes principales obtenues.
En effet, la combinaison lin√©aire des colonnes donnant naissance √† nos nouveaux axes a souvent un "sens" dans le monde r√©el :
- Soit parce qu'une petite poign√©e de variables repr√©sente la majorit√© de la composante
- Soit parce que la plupart des colonnes intervenant dans la composante somm√©e se combinent bien pour former une interpr√©tation naturelle.

Ici, cela pourrait par exemple √™tre :
- La 1√®re composante quasiment √©gale √† une somme des variables "Mange bio", "Mange de saison" et "Mange local", montrant ainsi que l'axe le plus discriminant serait le fait pour un individu de se nourrir de fa√ßon plus ou moins √©cologique.
- La 2√® composante d√©finie comme la somme pour tous les sports de la variable "Pratique x sport r√©guli√®rement", donnant ainsi un second axe discriminant les individus plus ou moins sportifs

Voyons ce que cela donne sur nos donn√©es. En utilisant la table ```composantes_principales```, repr√©sentez les 20 variables les plus importantes (en termes de poids absolu) pour la 1√®re composante de l'ACP, ainsi que leur contribution relative √† la composante. Plusieurs approches sont possibles ici, par exemple en fonction de si vous cherchez √† repr√©senter les contributions en valeur absolue ou non (autoriser les contributions n√©gatives est plus int√©ressant pour l'interpr√©tation des axes).


```R
nb_top_features <- 20

# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√© - Version simple</b></font> </summary>
<br>

```r
nb_top_features <- 20

fviz_contrib(acp, choice = "var", axes = 1, sort.val="desc", top = 20,
             title = paste(nb_top_features, "variables les plus repr√©sent√©es sur la PC1 - Contributions absolues"))

```

</details>

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√© - Version compl√®te</b></font> </summary>
<br>

```r
nb_top_features <- 20

# S√©lectionner les 20 caract√©ristiques les plus importantes pour PC1
pc1_features_abs <- abs(composantes_principales %>% select(PC1))
pc1_top_features_abs <- head(pc1_features_abs %>% arrange(desc(PC1)), nb_top_features)
pc1_top_features <- pc1_top_features_abs %>%
    rename(PC1_abs = PC1) %>%
    merge(composantes_principales, by = 'row.names', all = FALSE) %>%
    select(Row.names, PC1)

par(mar = c(5, 20, 5, 2))
barplot(pc1_top_features$PC1,
        horiz = TRUE,
        names.arg = pc1_top_features$Row.names,
        las = 1,
        main = paste(nb_top_features, "variables les plus repr√©sent√©es sur la PC1 - Contribution relative"),
        xlab = "Poids relatif",
        ylab = "Variables")

```

</details>

Faites ensuite la m√™me chose pour PC2 et pour PC3.


```R
# TODO
```

A pr√©sent, comment pouvez-vous interpr√©ter vos r√©sultats ?
√ätes-vous capables de donner un sens aux combinaisons lin√©aires obtenues ?
Peut-on renommer nos variables "PC1", "PC2, "PC3" ?

Si vous ne vous souvenez plus de la signification des variables, vous pouvez retrouver le dictionnaire des variables ici : https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

Il n'est pas garanti que vous retrouviez exactement les m√™mes r√©sultats, mais voici une proposition d'interpr√©tation suite √† l'ex√©cution des codes du corrig√© :
- PC1 : Une mesure agr√©g√©e repr√©sentant √† quel point l'individu a tendance √† produire lui-m√™me ce qu'il mange
    - Nombreuses variables commen√ßant par "autoproduction" et "autoconso" avec des poids positifs
- PC2 : Une mesure agr√©g√©e repr√©sentant √† quel point l'individu a tendance √† manger bio
    - Nombreuses variables contenant le mot "bio" avec des poids positifs
- PC3 : Plus difficile √† interpr√©ter, une mesure agr√©g√©e de pr√©f√©rences alimentaires li√©es aux produits frais
    - A quel point l'individu est-il prompt √† manger frais (fruits & l√©gumes, produits laitiers) ?

</details>

#### Et le clustering dans tout √ßa ?

Nous avons notre projection sur 2 ou 3 dimensions, nous avons interpr√©t√© ces nouveaux axes, il s'agit donc maintenant de faire ce pour quoi l'ACP a initialement √©t√© r√©alis√©e : l'observation des clusters.

Pour commencer, cr√©ez la table ```projection_individus_et_clusters``` concat√©nant les tables ```projection_individus```, ```clusters_kmeans``` et ```clusters_cah```:


```R
# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
projection_individus_et_clusters <- projection_individus

projection_individus_et_clusters$cluster_kmeans <- clusters_kmeans
projection_individus_et_clusters$cluster_cah <- clusters_cah
```

</details>

A pr√©sent, il ne vous reste plus qu'√† repr√©senter vos individus dans l'espace __2D__ g√©n√©r√© par les composantes PC1 et PC2. Concentrons-nous d'abord sur les clusters par K-moyennes : vous colorierez donc vos points en fonction de la valeur de la colonne 'cluster_kmeans'. A vous de jouer !

Bonus : N'h√©sitez pas √† renommer vos axes pour leur donner des noms plus explicites en fonction des interpr√©tations que vous avez faites pr√©c√©demment.


```R
# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
# Afficher le graphique des clusters en 2D
plot(projection_individus_et_clusters$PC1, projection_individus_et_clusters$PC2,
     col = projection_individus_et_clusters$cluster_kmeans,
     pch = 16,
     main = "Individus group√©s par tendances alimentaires",
     xlab = "PC1 - Production & consommation de sa propre nourriture",
     ylab = "PC2 - Consommation d'aliments bio")

legend("topright", legend = unique(projection_individus_et_clusters$cluster_kmeans),
       col = unique(projection_individus_et_clusters$cluster_kmeans),
       pch = 16,
       title = "Cluster (K-moyennes)")
```

</details>

Plut√¥t cool, non ?
La grande question maintenant : vos clusters se diff√©rencient-ils bien sur votre visualisation ? Si les choses sont bien faites, il devrait y avoir peu de superposition des diff√©rents groupes.

Pouvez-vous maintenant caract√©riser vos clusters en fonction de leur position sur votre graphe ? Vous avez ainsi vos _individus-types_ permettant de sch√©matiser votre population.

A pr√©sent, faites pareil sur les clusters obtenus par CAH, obtenez-vous exactement les m√™mes clusters ? L'interpr√©tation que vous avez faite change-t-elle ?


```R
# TODO
```

Pour terminer, quid d'utiliser notre 3√® composante principale dans notre repr√©sentation graphique ?
Cherchez sur Internet comment r√©aliser cette fois un graphe en __3 dimensions__ dans lequel repr√©senter vos individus.
Comment √©volue l'apparence de vos clusters ?


```R
# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√© - Version statique</b></font> </summary>
<br>

```r
# Afficher le graphique des clusters en 3D
library("scatterplot3d")

xs <- projection_individus_et_clusters$PC1
ys <- projection_individus_et_clusters$PC2
zs <- projection_individus_et_clusters$PC3

color <- projection_individus_et_clusters$cluster_kmeans

scatterplot3d(xs, ys, zs,
              color = color,
              pch = 16,
              main = "Individus group√©s par tendances alimentaires",
              xlab = "PC1 - Production & consommation de sa propre nourriture",
              ylab = "PC2 - Consommation d'aliments bio",
              zlab = "PC3 - Pr√©f√©rences produits frais")

```

</details>

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√© - Version interactive</b></font> </summary>
<br>

```r
library("plotly")

xs <- projection_individus_et_clusters$PC1
ys <- projection_individus_et_clusters$PC2
zs <- projection_individus_et_clusters$PC3

color <- projection_individus_et_clusters$cluster_kmeans

# Cr√©er un objet plotly avec les coordonn√©es x, y, z et la couleur
plot <- plot_ly(x = xs, y = ys, z = zs, color = color, type = "scatter3d", mode = "markers")

# D√©finir les √©tiquettes des axes
plot <- layout(plot, scene = list(xaxis = list(title = "PC1 - Production & consommation de sa propre nourriture"),
                                  yaxis = list(title = "PC2 - Consommation d'aliments bio"),
                                  zaxis = list(title = "PC3 - Pr√©f√©rences produits frais")))

# Afficher le graphique interactif
print(plot)
```

<br>

Si jamais le graphique n'est pas lisible dans l'output de la cellule, clic droit sur la cellule puis "Enable new view for cell output"

</details>

### 4. Pour aller plus loin

Vous avez √† pr√©sent termin√© la partie clustering du sujet. Si vous souhaitez aller plus loin, vous pouvez :

- Parcourir utilitR, et notamment la page [Analyse de donn√©es](https://www.book.utilitr.org/03_fiches_thematiques/fiche_analyse_de_donnees) et reproduire les visualisations pr√©sent√©es sur les donn√©es de la table ```habitudes_indiv```. Vous pouvez √©galement reprendre le sujet et utiliser des packages comme ```factoMineR``` ou bien ```factoExtra``` l√† o√π les corrig√©s ont √©t√© faits sans.
    + Parvenez-vous ainsi √† affiner vos conclusions pr√©c√©dentes ?

<br>

- Reproduire toutes les ex√©cutions en retirant seulement l'une des √©tapes du preprocessing, comme par exemple le traitement des outliers. Comment √©voluent alors les clusters et visualisations ?
    + Retirer les outliers peut souvent conduire √† la cr√©ation de clusters constitu√©s d'un seul individu, tr√®s √©loign√© des autres sur l'ACP. Il faut donc traiter ce type d'observations √† part ou bien augmenter le nombre de clusters pour compenser.

<br>
 
- Reproduire toutes les ex√©cutions en changeant le nombre de clusters ```k``` : comment √©voluent les clusters ? Que cela donne-t-il sur les ACP ?
    + Le cas ```k = 4``` est particuli√®rement int√©ressant : les clusters semblent se superposer sur les visualisations en 2D, mais on se rend compte lors de la visualisation 3D que les clusters pr√©tendumment superpos√©s se diff√©rencient en fait tr√®s bien si l'on rajoute la 3√® composante principale. Cela permet alors de caract√©riser encore plus finement nos individus types.

<br>

- Reproduire toutes les ex√©cutions sur une autre table que celles des habitudes alimentaires.
    + Nous vous recommandons par exemple d'essayer avec :
        - ```actphys_sedent``` : questionnaire sur l'activit√© physique des r√©pondants
        - ```fpq``` : questionnaire sur le fr√©quential alimentaire des individus
    + Comment les clusters s'interpr√®tent-ils alors ? Quels sont nos individus-types ?
    + Si vous souhaitez aller encore plus loin, vous pouvez faire une jointure sur les diff√©rentes tables et op√©rer le clustering sur la table jointe afin de voir quelles sont les caract√©ristiques les plus discriminantes.
    + Pour les autres tables, attention √† ne bien garder que des variables num√©riques, et par exemple faire du _one-hot encoding_ sur les variables cat√©gorielles cod√©es sur des nombres entre 1 et 10.

Maintenant, cr√©ez votre propre carte ! Vous pouvez regarder directement dans le dictionnaire des variables, ou bien vous aider des libell√©s.
Les fr√©quences en nombre de jours par mois finissent par _freq_M, et les indicatrices de consommation finissent par _ON (ces derni√®res valent 1 si le produit est consomm√© et 0 sinon). 

Par exemple, on peut choisir parmi les variables dans : ```colnames(fpq)```

Maintenant, cr√©ez votre propre carte ! Vous pouvez regarder directement dans le dictionnaire des variables, ou bien vous aider des libell√©s.
Les fr√©quences en nombre de jours par mois finissent par _freq_M, et les indicatrices de consommation finissent par _ON (ces derni√®res valent 1 si le produit est consomm√© et 0 sinon). 

Par exemple, on peut choisir parmi les variables dans : ```colnames(fpq)```


```R
# TODO
```

# Fin :)

Si vous voulez toucher √† de la r√©gression et de l'apprentissage supervis√©, n'h√©sitez pas √† revisiter le sujet en Python !

# Funathon 2023 - Sujet 3

Responsables :
- Julie Sixou, D2E
- Antoine Palazzolo, SSP Lab
- Thomas Faria, SSP Lab

# Habitudes alimentaires √† partir des donn√©es INCA

## Avant de commencer...

Ce sujet est disponible dans 2 langages : R et Python.
Ce notebook correspond √† la version R, qui est la plus r√©duite des deux. En effet, la partie 3 sur les premiers pas en Machine Learning est sp√©cifique √† Python.

Il s'agit l√† principalement d'une initiation √† l'analyse de donn√©es et √† la data visualization, √† travers l'√©tude des donn√©es de consommations et habitudes alimentaires de l'[√©tude INCA 3](https://www.data.gouv.fr/fr/datasets/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/).
Le sujet est constitu√©e de 3 parties distinctes et ind√©pendantes :
- Analyse exploratoire des donn√©es et visualisations
- Clustering d'individus : ACP, K-moyennes, Clustering Ascendant Hi√©rarchique
- __Absente du sujet en R__ : _Pr√©diction de l'IMC : premiers pas vers les m√©thodes de ML supervis√©_

Il est √©galement possible de ne faire qu'une ou deux parties du sujet. A noter que les corrig√©s pr√©sent√©s dans le sujet ne sont qu'une suggestion de comment r√©pondre aux questions pos√©es, mais qu'il existe √©videmment d'autres mani√®res de faire, parfois m√™me bien meilleures.

Si jamais vous n'√™tes pas familiers avec R, nous ne saurions que trop vous recommander de jeter un oeil aux ressources suivantes :
- D√©buter avec R : https://www.utilitr.org/
- Bonnes pratiques en R : https://www.pratiques.utilitr.org/

Pour en savoir plus sur les donn√©es utilis√©es pour ce sujet et sur le contexte de l'√©tude : https://www.data.gouv.fr/fr/datasets/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/

Pour lire la documentation associ√©e aux donn√©es : https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf

### Imports

Ex√©cutez √† pr√©sent la cellule ci-dessous pour installer les packages n√©cessaires au sujet :


```R
# Lecture du fichier requirements.txt
requirements <- readLines("requirements_R.txt")

# Installation des packages
for (package in requirements) {
  install.packages(package)
}
```

    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    
    Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô
    (as ‚Äòlib‚Äô is unspecified)
    


Ex√©cutez √©galement les cellules ci-dessous pour importer l'ensemble des jeux de donn√©es n√©cessaires √† l'√©tude :


```R
library(aws.s3)
library(dplyr)
library(readr)
```

    
    Attaching package: ‚Äòdplyr‚Äô
    
    
    The following objects are masked from ‚Äòpackage:stats‚Äô:
    
        filter, lag
    
    
    The following objects are masked from ‚Äòpackage:base‚Äô:
    
        intersect, setdiff, setequal, union
    
    


#### Imports des donn√©es avec s3

A favoriser, en utilisant les donn√©es d√©j√† import√©es sur le Datalab


```R
bucket <- "projet-funathon"
path_data <- "2023/sujet3/diffusion"
```


```R
description_indiv <- s3read_using(read_delim, object = paste(path_data, "description-indiv.csv", sep="/"), bucket = bucket, opts = list('region'=''), show_col_types = FALSE)
habitudes_indiv <- s3read_using(read_delim, object = paste(path_data, "habitudes-indiv.csv", sep="/"), bucket = bucket, opts = list('region'=''), show_col_types = FALSE)
actphys_sedent <- s3read_using(read_delim, object = paste(path_data, "actphys-sedent.csv", sep="/"), bucket = bucket, opts = list('region'=''), show_col_types = FALSE)
fpq <- s3read_using(read_delim, object = paste(path_data, "fpq.csv", sep="/"), bucket = bucket, opts = list('region'=''), show_col_types = FALSE)
```

    Warning message:
    ‚Äú[1m[22mOne or more parsing issues, call `problems()` on your data frame for details,
    e.g.:
      dat <- vroom(...)
      problems(dat)‚Äù
    Warning message:
    ‚Äú[1m[22mOne or more parsing issues, call `problems()` on your data frame for details,
    e.g.:
      dat <- vroom(...)
      problems(dat)‚Äù
    Warning message:
    ‚Äú[1m[22mOne or more parsing issues, call `problems()` on your data frame for details,
    e.g.:
      dat <- vroom(...)
      problems(dat)‚Äù



```R
head(description_indiv)
str(description_indiv)
```


<table class="dataframe">
<caption>A tibble: 6 √ó 185</caption>
<thead>
	<tr><th scope=col>NOMEN</th><th scope=col>NOIND</th><th scope=col>ech</th><th scope=col>enf_allaite</th><th scope=col>pop1</th><th scope=col>pop2</th><th scope=col>pop3</th><th scope=col>pond_indiv_adu_pop1</th><th scope=col>pond_indiv_enf_pop1</th><th scope=col>pond_indiv_adu_pop2</th><th scope=col>‚ãØ</th><th scope=col>fume_age_debut_nsp</th><th scope=col>fume_age_arret</th><th scope=col>fume_age_arret_nsp</th><th scope=col>bmr_kcal</th><th scope=col>sousest0</th><th scope=col>surest0</th><th scope=col>sousest1</th><th scope=col>sousest3</th><th scope=col>sousext</th><th scope=col>surext</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>‚ãØ</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>1101001</td><td>110100101</td><td>1</td><td>NA</td><td>1</td><td>1</td><td>1</td><td>11415.498</td><td>NA</td><td>18553.734</td><td>‚ãØ</td><td>NA</td><td>NA</td><td>NA</td><td>1378.093</td><td> 0</td><td> 0</td><td> 0</td><td>NA</td><td> 0</td><td> 0</td></tr>
	<tr><td>1101007</td><td>110100701</td><td>1</td><td>NA</td><td>1</td><td>1</td><td>1</td><td> 4644.245</td><td>NA</td><td> 4656.461</td><td>‚ãØ</td><td>NA</td><td>NA</td><td>NA</td><td>1352.780</td><td> 1</td><td> 0</td><td> 1</td><td>NA</td><td> 0</td><td> 0</td></tr>
	<tr><td>1101008</td><td>110100801</td><td>1</td><td>NA</td><td>1</td><td>1</td><td>1</td><td> 6016.880</td><td>NA</td><td> 6307.757</td><td>‚ãØ</td><td>NA</td><td>33</td><td>NA</td><td>1630.974</td><td> 0</td><td> 0</td><td> 0</td><td>NA</td><td> 0</td><td> 0</td></tr>
	<tr><td>1101012</td><td>110101201</td><td>1</td><td>NA</td><td>1</td><td>1</td><td>1</td><td> 1782.446</td><td>NA</td><td> 2041.063</td><td>‚ãØ</td><td>NA</td><td>NA</td><td>NA</td><td>1749.460</td><td> 0</td><td> 0</td><td> 0</td><td>NA</td><td> 0</td><td> 0</td></tr>
	<tr><td>1101014</td><td>110101401</td><td>1</td><td>NA</td><td>1</td><td>1</td><td>1</td><td> 2359.106</td><td>NA</td><td> 2455.424</td><td>‚ãØ</td><td>NA</td><td>NA</td><td>NA</td><td>1090.112</td><td> 0</td><td> 0</td><td> 0</td><td>NA</td><td> 0</td><td> 0</td></tr>
	<tr><td>1101016</td><td>110101601</td><td>1</td><td>NA</td><td>1</td><td>1</td><td>0</td><td>13623.502</td><td>NA</td><td>16412.590</td><td>‚ãØ</td><td>NA</td><td>NA</td><td>NA</td><td>      NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>
</tbody>
</table>



    spc_tbl_ [5,855 √ó 185] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
     $ NOMEN                        : num [1:5855] 1101001 1101007 1101008 1101012 1101014 ...
     $ NOIND                        : num [1:5855] 1.1e+08 1.1e+08 1.1e+08 1.1e+08 1.1e+08 ...
     $ ech                          : num [1:5855] 1 1 1 1 1 1 1 1 1 1 ...
     $ enf_allaite                  : num [1:5855] NA NA NA NA NA NA NA NA NA NA ...
     $ pop1                         : num [1:5855] 1 1 1 1 1 1 1 1 1 1 ...
     $ pop2                         : num [1:5855] 1 1 1 1 1 1 1 0 1 1 ...
     $ pop3                         : num [1:5855] 1 1 1 1 1 0 0 0 1 1 ...
     $ pond_indiv_adu_pop1          : num [1:5855] 11415 4644 6017 1782 2359 ...
     $ pond_indiv_enf_pop1          : num [1:5855] NA NA NA NA NA NA NA NA NA NA ...
     $ pond_indiv_adu_pop2          : num [1:5855] 18554 4656 6308 2041 2455 ...
     $ pond_indiv_enf_pop2          : num [1:5855] NA NA NA NA NA NA NA NA NA NA ...
     $ pond_indiv_adu_pop3          : num [1:5855] 20744 6559 11348 2783 5051 ...
     $ pond_indiv_enf_pop3          : num [1:5855] NA NA NA NA NA NA NA NA NA NA ...
     $ pond_men_pop1                : num [1:5855] 397 1562 438 1612 1671 ...
     $ pond_men_pop2                : num [1:5855] 562 1679 613 1682 1966 ...
     $ zae                          : chr [1:5855] "Z01091" "Z01091" "Z01091" "Z01091" ...
     $ strate                       : num [1:5855] 6 6 6 6 6 6 6 1 3 3 ...
     $ fpc1                         : num [1:5855] 0.0383 0.0383 0.0383 0.0383 0.0383 ...
     $ fpc2                         : num [1:5855] 0.166 0.166 0.166 0.166 0.166 ...
     $ fpc3                         : num [1:5855] 0.333 0.5 0.5 1 0.5 ...
     $ saison_pop1                  : num [1:5855] 1 1 1 1 1 3 3 2 1 2 ...
     $ saison_pop2                  : num [1:5855] 1 1 1 1 1 3 3 NA 2 2 ...
     $ saison_pop3                  : num [1:5855] 1 1 1 1 3 NA NA NA 1 2 ...
     $ region_adm_12cl              : num [1:5855] 9 9 9 9 9 9 9 6 9 9 ...
     $ region_inca3                 : num [1:5855] 6 6 6 6 6 6 6 1 3 3 ...
     $ agglo_5cl                    : num [1:5855] 1 1 1 1 1 1 1 1 2 2 ...
     $ sex_PS                       : num [1:5855] 1 2 1 1 2 2 1 1 1 1 ...
     $ tage_PS                      : num [1:5855] 7 8 8 8 9 8 7 8 8 9 ...
     $ tage_PS_mois                 : num [1:5855] NA NA NA NA NA NA NA NA NA NA ...
     $ lien_rep_enf                 : num [1:5855] NA NA NA NA NA NA NA NA NA NA ...
     $ diplome_interv               : num [1:5855] 7 7 7 10 7 3 9 11 7 6 ...
     $ etude_4cl_interv             : num [1:5855] 1 1 1 3 1 1 2 4 1 1 ...
     $ situ_prof_5cl_interv         : num [1:5855] 3 1 1 1 4 1 1 1 2 4 ...
     $ atrav_interv                 : num [1:5855] 2 NA NA NA 1 NA NA NA 1 1 ...
     $ trav_nuit_interv             : num [1:5855] NA 4 4 4 NA 4 4 4 NA NA ...
     $ trav_nuit_2cl_interv         : num [1:5855] NA 2 2 2 NA 2 2 2 NA NA ...
     $ PCS_8cl_interv               : num [1:5855] 8 1 2 1 7 1 1 5 2 7 ...
     $ PCS_4cl_interv               : num [1:5855] 4 1 1 1 4 1 1 3 1 4 ...
     $ tps_travail_interv           : num [1:5855] NA 2 1 1 1 1 1 1 1 1 ...
     $ vacances_interv              : num [1:5855] 2 1 1 1 1 2 1 1 2 2 ...
     $ interv_PR                    : num [1:5855] 0 0 1 1 0 0 1 1 0 1 ...
     $ sex_PR                       : num [1:5855] 1 1 1 1 1 1 1 1 2 1 ...
     $ tage_PR                      : num [1:5855] 2 2 2 2 3 1 1 2 2 3 ...
     $ lien_interv_PR               : num [1:5855] 2 1 NA NA 1 1 NA NA 1 NA ...
     $ lien_PS_PR                   : num [1:5855] 2 1 NA NA 1 1 NA NA 1 NA ...
     $ diplome_PR                   : num [1:5855] 7 7 7 10 3 8 9 11 2 6 ...
     $ etude_4cl_PR                 : num [1:5855] 1 1 1 3 1 2 2 4 1 1 ...
     $ atrav_PR                     : num [1:5855] NA 1 NA NA 1 NA NA NA 1 1 ...
     $ PCS_8cl_PR                   : num [1:5855] 2 7 2 1 7 2 1 5 7 7 ...
     $ PCS_4cl_PR                   : num [1:5855] 1 4 1 1 4 1 1 3 4 4 ...
     $ tps_travail_PR               : num [1:5855] 1 1 1 1 1 1 1 1 1 1 ...
     $ stat_log_2cl                 : num [1:5855] 2 1 1 2 1 2 2 2 1 1 ...
     $ soins                        : num [1:5855] 2 2 2 2 2 2 2 2 1 2 ...
     $ situ_fin_3cl                 : num [1:5855] 2 1 1 1 2 2 1 1 2 2 ...
     $ revenu                       : num [1:5855] 12 11 11 11 6 12 11 12 6 8 ...
     $ RUC_4cl                      : num [1:5855] 3 4 2 4 1 3 2 2 1 2 ...
     $ nbpers                       : num [1:5855] 4 2 4 1 2 4 4 6 2 2 ...
     $ nbadu                        : num [1:5855] 3 2 2 1 2 2 2 3 2 2 ...
     $ nbenf                        : num [1:5855] 1 0 2 0 0 2 2 3 0 0 ...
     $ situ_alim_statut             : num [1:5855] 1 1 1 1 1 1 1 1 3 2 ...
     $ IA_statut                    : num [1:5855] 0 0 0 0 0 0 0 0 2 0 ...
     $ IA_score                     : num [1:5855] NA NA NA NA NA ...
     $ taille_m                     : num [1:5855] 168 166 162 177 152 158 174 186 168 173 ...
     $ taille_d                     : num [1:5855] NA NA NA NA NA NA NA NA NA NA ...
     $ taille                       : num [1:5855] 168 166 162 177 152 158 174 186 168 173 ...
     $ poids_m                      : num [1:5855] 51.6 65.1 78.6 81.9 51.8 NA 79.5 92 59.1 85.6 ...
     $ poids_d                      : num [1:5855] NA NA NA NA NA 60 NA NA NA NA ...
     $ poids                        : num [1:5855] 51.6 65.1 78.6 81.9 51.8 ...
     $ imc                          : num [1:5855] 18.3 23.6 29.9 26.1 22.4 ...
     $ statnut                      : num [1:5855] 0 1 3 3 1 1 3 3 1 3 ...
     $ maladie_allergie_alim        : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ intoall_confirm_med          : num [1:5855] NA NA NA NA NA NA NA NA NA NA ...
     $ regime_vegetarien            : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ regime_allergie              : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ regime_maigrir_med           : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ regime_maigrir_choix         : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ regime_autre_med             : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ regime_raisonmed_libelle     : chr [1:5855] NA NA NA NA ...
     $ regime_poidsstable           : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ regime_forme                 : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ regime_autreraison           : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ regime_non                   : num [1:5855] 1 1 1 1 1 1 1 NA 1 1 ...
     $ veget_viande                 : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ veget_prodmer                : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ veget_prodlait               : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ veget_oeuf                   : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ veget_miel                   : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ veget_autre_alim             : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ veget_autre_alim_libelle     : logi [1:5855] NA NA NA NA NA NA ...
     $ allergie_laitvache           : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ allergie_prepainfsoja        : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ allergie_prepainfamande      : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ allergie_gluten              : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ allergie_farineble           : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ allergie_lupin               : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ allergie_arachide            : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ allergie_fruitcoque          : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
     $ allergie_fruitcoque_libelle  : chr [1:5855] NA NA NA NA ...
     $ allergie_oeuf                : num [1:5855] 0 0 0 0 0 0 0 NA 0 0 ...
      [list output truncated]
     - attr(*, "spec")=
      .. cols(
      ..   NOMEN = [32mcol_double()[39m,
      ..   NOIND = [32mcol_double()[39m,
      ..   ech = [32mcol_double()[39m,
      ..   enf_allaite = [32mcol_double()[39m,
      ..   pop1 = [32mcol_double()[39m,
      ..   pop2 = [32mcol_double()[39m,
      ..   pop3 = [32mcol_double()[39m,
      ..   pond_indiv_adu_pop1 = [32mcol_double()[39m,
      ..   pond_indiv_enf_pop1 = [32mcol_double()[39m,
      ..   pond_indiv_adu_pop2 = [32mcol_double()[39m,
      ..   pond_indiv_enf_pop2 = [32mcol_double()[39m,
      ..   pond_indiv_adu_pop3 = [32mcol_double()[39m,
      ..   pond_indiv_enf_pop3 = [32mcol_double()[39m,
      ..   pond_men_pop1 = [32mcol_double()[39m,
      ..   pond_men_pop2 = [32mcol_double()[39m,
      ..   zae = [31mcol_character()[39m,
      ..   strate = [32mcol_double()[39m,
      ..   fpc1 = [32mcol_double()[39m,
      ..   fpc2 = [32mcol_double()[39m,
      ..   fpc3 = [32mcol_double()[39m,
      ..   saison_pop1 = [32mcol_double()[39m,
      ..   saison_pop2 = [32mcol_double()[39m,
      ..   saison_pop3 = [32mcol_double()[39m,
      ..   region_adm_12cl = [32mcol_double()[39m,
      ..   region_inca3 = [32mcol_double()[39m,
      ..   agglo_5cl = [32mcol_double()[39m,
      ..   sex_PS = [32mcol_double()[39m,
      ..   tage_PS = [32mcol_double()[39m,
      ..   tage_PS_mois = [32mcol_double()[39m,
      ..   lien_rep_enf = [32mcol_double()[39m,
      ..   diplome_interv = [32mcol_double()[39m,
      ..   etude_4cl_interv = [32mcol_double()[39m,
      ..   situ_prof_5cl_interv = [32mcol_double()[39m,
      ..   atrav_interv = [32mcol_double()[39m,
      ..   trav_nuit_interv = [32mcol_double()[39m,
      ..   trav_nuit_2cl_interv = [32mcol_double()[39m,
      ..   PCS_8cl_interv = [32mcol_double()[39m,
      ..   PCS_4cl_interv = [32mcol_double()[39m,
      ..   tps_travail_interv = [32mcol_double()[39m,
      ..   vacances_interv = [32mcol_double()[39m,
      ..   interv_PR = [32mcol_double()[39m,
      ..   sex_PR = [32mcol_double()[39m,
      ..   tage_PR = [32mcol_double()[39m,
      ..   lien_interv_PR = [32mcol_double()[39m,
      ..   lien_PS_PR = [32mcol_double()[39m,
      ..   diplome_PR = [32mcol_double()[39m,
      ..   etude_4cl_PR = [32mcol_double()[39m,
      ..   atrav_PR = [32mcol_double()[39m,
      ..   PCS_8cl_PR = [32mcol_double()[39m,
      ..   PCS_4cl_PR = [32mcol_double()[39m,
      ..   tps_travail_PR = [32mcol_double()[39m,
      ..   stat_log_2cl = [32mcol_double()[39m,
      ..   soins = [32mcol_double()[39m,
      ..   situ_fin_3cl = [32mcol_double()[39m,
      ..   revenu = [32mcol_double()[39m,
      ..   RUC_4cl = [32mcol_double()[39m,
      ..   nbpers = [32mcol_double()[39m,
      ..   nbadu = [32mcol_double()[39m,
      ..   nbenf = [32mcol_double()[39m,
      ..   situ_alim_statut = [32mcol_double()[39m,
      ..   IA_statut = [32mcol_double()[39m,
      ..   IA_score = [32mcol_double()[39m,
      ..   taille_m = [32mcol_double()[39m,
      ..   taille_d = [32mcol_double()[39m,
      ..   taille = [32mcol_double()[39m,
      ..   poids_m = [32mcol_double()[39m,
      ..   poids_d = [32mcol_double()[39m,
      ..   poids = [32mcol_double()[39m,
      ..   imc = [32mcol_double()[39m,
      ..   statnut = [32mcol_double()[39m,
      ..   maladie_allergie_alim = [32mcol_double()[39m,
      ..   intoall_confirm_med = [32mcol_double()[39m,
      ..   regime_vegetarien = [32mcol_double()[39m,
      ..   regime_allergie = [32mcol_double()[39m,
      ..   regime_maigrir_med = [32mcol_double()[39m,
      ..   regime_maigrir_choix = [32mcol_double()[39m,
      ..   regime_autre_med = [32mcol_double()[39m,
      ..   regime_raisonmed_libelle = [31mcol_character()[39m,
      ..   regime_poidsstable = [32mcol_double()[39m,
      ..   regime_forme = [32mcol_double()[39m,
      ..   regime_autreraison = [32mcol_double()[39m,
      ..   regime_non = [32mcol_double()[39m,
      ..   veget_viande = [32mcol_double()[39m,
      ..   veget_prodmer = [32mcol_double()[39m,
      ..   veget_prodlait = [32mcol_double()[39m,
      ..   veget_oeuf = [32mcol_double()[39m,
      ..   veget_miel = [32mcol_double()[39m,
      ..   veget_autre_alim = [32mcol_double()[39m,
      ..   veget_autre_alim_libelle = [33mcol_logical()[39m,
      ..   allergie_laitvache = [32mcol_double()[39m,
      ..   allergie_prepainfsoja = [32mcol_double()[39m,
      ..   allergie_prepainfamande = [32mcol_double()[39m,
      ..   allergie_gluten = [32mcol_double()[39m,
      ..   allergie_farineble = [32mcol_double()[39m,
      ..   allergie_lupin = [32mcol_double()[39m,
      ..   allergie_arachide = [32mcol_double()[39m,
      ..   allergie_fruitcoque = [32mcol_double()[39m,
      ..   allergie_fruitcoque_libelle = [31mcol_character()[39m,
      ..   allergie_oeuf = [32mcol_double()[39m,
      ..   allergie_poisson = [32mcol_double()[39m,
      ..   allergie_crustace = [32mcol_double()[39m,
      ..   allergie_mollusque = [32mcol_double()[39m,
      ..   allergie_soja = [32mcol_double()[39m,
      ..   allergie_sesame = [32mcol_double()[39m,
      ..   allergie_moutarde = [32mcol_double()[39m,
      ..   allergie_sulfite = [32mcol_double()[39m,
      ..   allergie_celeri = [32mcol_double()[39m,
      ..   allergie_autres_fruitleg = [32mcol_double()[39m,
      ..   allergie_autres_fl_libelle = [31mcol_character()[39m,
      ..   allergie_autresalim = [32mcol_double()[39m,
      ..   allergie_autresalim_libelle = [31mcol_character()[39m,
      ..   allergie_nondetermine = [32mcol_double()[39m,
      ..   allergie_fruits = [32mcol_double()[39m,
      ..   allergie_legumes = [32mcol_double()[39m,
      ..   regime_passe = [32mcol_double()[39m,
      ..   regime_nb_2dernann = [32mcol_double()[39m,
      ..   regime_nb_anter2dernann = [32mcol_double()[39m,
      ..   regime_type = [32mcol_double()[39m,
      ..   regime_type_libelle = [31mcol_character()[39m,
      ..   regime_duree_sem = [32mcol_double()[39m,
      ..   regime_duree_mois = [32mcol_double()[39m,
      ..   regime_duree_nsp = [32mcol_double()[39m,
      ..   poids_anndern = [32mcol_double()[39m,
      ..   poids_anndern_nsp = [32mcol_double()[39m,
      ..   poids_modif = [32mcol_double()[39m,
      ..   poids_modifalim = [32mcol_double()[39m,
      ..   poids_plusAP = [32mcol_double()[39m,
      ..   poids_medicaments = [32mcol_double()[39m,
      ..   poids_substituts = [32mcol_double()[39m,
      ..   poids_chirurgie = [32mcol_double()[39m,
      ..   poids_modifalim_laityaourt = [32mcol_double()[39m,
      ..   poids_modifalim_fromage = [32mcol_double()[39m,
      ..   poids_modifalim_mg = [32mcol_double()[39m,
      ..   poids_modifalim_fruit = [32mcol_double()[39m,
      ..   poids_modifalim_legume = [32mcol_double()[39m,
      ..   poids_modifalim_pdtfeculent = [32mcol_double()[39m,
      ..   poids_modifalim_pizza = [32mcol_double()[39m,
      ..   poids_modifalim_pain = [32mcol_double()[39m,
      ..   poids_modifalim_vrouge = [32mcol_double()[39m,
      ..   poids_modifalim_volaille = [32mcol_double()[39m,
      ..   poids_modifalim_oeuf = [32mcol_double()[39m,
      ..   poids_modifalim_gateau = [32mcol_double()[39m,
      ..   poids_modifalim_edulcorant = [32mcol_double()[39m,
      ..   poids_modifalim_pdtsalleges = [32mcol_double()[39m,
      ..   poids_modifalim_BS = [32mcol_double()[39m,
      ..   poids_modifalim_eau = [32mcol_double()[39m,
      ..   poids_modifalim_autre = [32mcol_double()[39m,
      ..   poids_modifalim_autre_libelle = [31mcol_character()[39m,
      ..   poids_perception = [32mcol_double()[39m,
      ..   poidsmax = [32mcol_double()[39m,
      ..   poidsmax_nsp = [32mcol_double()[39m,
      ..   age_poidsmax = [32mcol_double()[39m,
      ..   age_poidsmax_nsp = [32mcol_double()[39m,
      ..   poidsmin = [32mcol_double()[39m,
      ..   poidsmin_nsp = [32mcol_double()[39m,
      ..   age_poidsmin = [32mcol_double()[39m,
      ..   age_poidsmin_nsp = [32mcol_double()[39m,
      ..   nb_prise_10kg = [32mcol_double()[39m,
      ..   menopause = [32mcol_double()[39m,
      ..   enceinte = [32mcol_double()[39m,
      ..   enceinte_nbmois = [32mcol_double()[39m,
      ..   allaite = [32mcol_double()[39m,
      ..   allaite_nbsem = [33mcol_logical()[39m,
      ..   enceinte_12dermois = [32mcol_double()[39m,
      ..   fume = [32mcol_double()[39m,
      ..   nb_cigarettes_jour = [32mcol_double()[39m,
      ..   nb_cigarettes_sem = [32mcol_double()[39m,
      ..   nb_cigarettes_nsp = [32mcol_double()[39m,
      ..   nb_cigares_jour = [32mcol_double()[39m,
      ..   nb_cigares_sem = [32mcol_double()[39m,
      ..   nb_cigares_nsp = [32mcol_double()[39m,
      ..   nb_pipes_jour = [32mcol_double()[39m,
      ..   nb_pipes_sem = [32mcol_double()[39m,
      ..   nb_pipes_nsp = [32mcol_double()[39m,
      ..   fume_age_debut = [32mcol_double()[39m,
      ..   fume_age_debut_nsp = [32mcol_double()[39m,
      ..   fume_age_arret = [32mcol_double()[39m,
      ..   fume_age_arret_nsp = [32mcol_double()[39m,
      ..   bmr_kcal = [32mcol_double()[39m,
      ..   sousest0 = [32mcol_double()[39m,
      ..   surest0 = [32mcol_double()[39m,
      ..   sousest1 = [32mcol_double()[39m,
      ..   sousest3 = [32mcol_double()[39m,
      ..   sousext = [32mcol_double()[39m,
      ..   surext = [32mcol_double()[39m
      .. )
     - attr(*, "problems")=<externalptr> 


#### Imports des donn√©es depuis data.gouv.fr

Eviter cette option pour ne pas surcharger le SSP Cloud si trop de participants font des t√©l√©chargements en m√™me temps. A n'utiliser que si impossibilit√© d'utiliser le Datalab.

```r
# Lecture des fichiers CSV
description_indiv <- read_delim("https://www.data.gouv.fr/fr/datasets/r/f982ee4a-b2db-4608-ab95-bfe51dfc4897", delim=";")
habitudes_indiv <- read_delim("https://www.data.gouv.fr/fr/datasets/r/099351b9-e32e-4e38-8f23-dec21fd07c71", delim=";")
actphys_sedent <- read_delim("https://www.data.gouv.fr/fr/datasets/r/e9a34b81-2105-4d82-a023-c14947fb2b2c", delim=";")
fpq <- read_delim("https://www.data.gouv.fr/fr/datasets/r/32e79499-9897-423b-acd6-143121340f86", delim=";")
```

## Partie 1 : Analyse exploratoire des donn√©es et visualisations

Premier point de contact : Julie Sixou

Bo√Æte √† outils de ce qu'il est possible de faire avec ```dplyr``` et ```ggplot2```

Explorons la base de donn√©es INCA3 : dans cette partie, nous allons vous montrer comment produire des graphes et statistiques univari√©es et bivari√©es.

Le dictionnaire des variables et des modalit√©s peut se trouver ici : https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf
<br>

### Imports


```R
# Import des librairies

library(ggplot2)
library(ggcorrplot)
library(sf)
```

    Linking to GEOS 3.10.2, GDAL 3.4.1, PROJ 8.2.1; sf_use_s2() is TRUE
    



```R
# Option d'affichage
options(dplyr.width = Inf)
options(repr.plot.width=20, repr.plot.height=10)
```

### 1. Statistiques univari√©es avec la table _description_indiv_

Quelques exemples de ce qu'il est possible de faire avec ```ggplot2``` :


```R
# Histogramme des IMC

ggplot(data=description_indiv,aes(x=imc))+
    geom_histogram(binwidth=1,color="grey",fill="lightblue")
```

    Warning message:
    ‚Äú[1m[22mRemoved 14 rows containing non-finite values (`stat_bin()`).‚Äù



    
![png](output_195_1.png)
    



```R
# Histogramme des niveaux de dipl√¥me

ggplot(data=description_indiv,aes(x=diplome_interv))+ 
    geom_histogram(binwidth=1,color="black",fill="darkred")+
    labs(title="Histogramme des niveaux de dipl√¥me",  # cette fois on rajoute des l√©gendes
    x="Code du niveau de dipl√¥me",
    y="Nombre d'individus")
```

    Warning message:
    ‚Äú[1m[22mRemoved 1 rows containing non-finite values (`stat_bin()`).‚Äù



    
![png](output_196_1.png)
    


Recodons la variable des niveaux de dipl√¥me pour mieux comprendre le graphe :


```R
# Recodage des niveaux de dipl√¥me

description_indiv <- description_indiv %>% mutate(categorie_diplome=case_when(diplome_interv==1 ~ "Aucun dipl√¥me, n'a jamais √©t√© scolaris√©",
                                                                              diplome_interv==2 ~ "Aucun dipl√¥me, scolarit√© s'est arr√™t√©e √† l'√©cole primaire",
                                                                              diplome_interv==3 ~ "Aucun dipl√¥me, scolarit√© s'est arr√™t√©e au coll√®ge",
                                                                              diplome_interv==4 ~ "Aucun dipl√¥me, scolarit√© s'est arr√™t√©e au del√† du coll√®ge",
                                                                              diplome_interv==5 ~ "Aucun dipl√¥me, sans pr√©cision",
                                                                              diplome_interv==6 ~ "CEP",
                                                                              diplome_interv==7 ~ "CAP, BEP, BEPC, brevet √©l√©mentaire, brevet de compagnon",
                                                                              diplome_interv==8 ~ "Baccalaur√©at technologique ou professionnel,\nBrevet professionnel ou de technicien,\nBEA, BEC, BEI, BEH, capacit√© en droit",
                                                                              diplome_interv==9 ~ "Baccalaur√©at g√©n√©ral",
                                                                              diplome_interv==10 ~ "Dipl√¥me de 1er cycle universitaire (Bac +3, licence),\nBTS, DUT, DEST, DEUG, dipl√¥me des professions\nsociales ou de la sant√©, d'infirmier",
                                                                              diplome_interv==11 ~ "Dipl√¥me de 2√®me cycle universitaire (Bac+4, Bac+5),\nMaster, Ma√Ætrise, dipl√¥me d'ing√©nieur,\nd'une grande √©cole",
                                                                              diplome_interv==12 ~ "Dipl√¥me de 3√®me cycle universitaire (>Bac+5, doctorat),\ndipl√¥me de v√©t√©rinaire, m√©decin, pharmacien",
                                                                              diplome_interv==13 ~ "Refus",
                                                                              diplome_interv==14 ~ "Ne sait pas"))
```


```R
# Tableau des fr√©quences de chaque cat√©gorie de diplome
counts_diplome <- description_indiv %>% group_by(categorie_diplome) %>% summarise(n=n())

# Graphique en barres horizontales
ggplot(data=counts_diplome,aes(x=categorie_diplome,y=n))+
    geom_histogram(stat="identity")+
coord_flip()+
labs(title="Histogramme des niveaux de dipl√¥me",
     x="Libelle du niveau de dipl√¥me",
     y="Nombre d'individus")
```

    Warning message in geom_histogram(stat = "identity"):
    ‚Äú[1m[22mIgnoring unknown parameters: `binwidth`, `bins`, and `pad`‚Äù



    
![png](output_199_1.png)
    



```R
# Recodage de la variable de type d'agglom√©ration

description_indiv <- description_indiv %>% mutate(categorie_agglo = case_when(agglo_5cl==1 ~ "Rural",
                                                                             agglo_5cl==2 ~ "2000 - 19 999 hab",
                                                                             agglo_5cl==3 ~ "20 000 - 99 999 hab",
                                                                             agglo_5cl==4 ~ "+ 100 000 hab",
                                                                             agglo_5cl==5 ~ "Paris"))
```


```R
counts_agglo <- description_indiv %>% group_by(categorie_agglo) %>% summarise(n=n())

# G√©n√©rer le graphique en barres horizontales
ggplot(data=counts_agglo,aes(x=categorie_agglo,y=n))+
    geom_histogram(stat="identity")+
    coord_flip()+ 
    labs(title="Histogramme des types d'agglom√©ration",
          x="Type d'agglom√©ration",
          y="Nombre d'individus")
```

    Warning message in geom_histogram(stat = "identity"):
    ‚Äú[1m[22mIgnoring unknown parameters: `binwidth`, `bins`, and `pad`‚Äù



    
![png](output_201_1.png)
    


A vous de jouer, faites la m√™me chose pour les tranches de revenu : histogramme de la variable **RUC_4cl** qui donne le revenu mensuel total du foyer par unit√© de consommation (UC) en 4 classes. Les modalit√©s de la variable sont les suivantes :


```R
# Niveau de vie

description_indiv <- description_indiv %>% mutate(categorie_ruc=case_when(RUC_4cl==1 ~ "<900 ‚Ç¨/mois/UC",
                                                                         RUC_4cl==2 ~ "[900-1 340[ ‚Ç¨/mois/UC",
                                                                         RUC_4cl==3 ~ "[1 340-1 850[ ‚Ç¨/mois/U",
                                                                         RUC_4cl==4 ~ ">=1 850 ‚Ç¨/mois/UC"))

```


```R
# TODO
counts_ruc <- description_indiv %>% group_by(categorie_ruc) %>% summarise(n=n())

# G√©n√©rer le graphique en barres horizontales
ggplot(data=counts_ruc,aes(x=categorie_ruc,y=n))+
    geom_histogram(stat="identity")+
    coord_flip()+ 
    labs(title="Histogramme des niveaux de revenus",
          x="Tranches de revenu",
          y="Nombre d'individus")
```

    Warning message in geom_histogram(stat = "identity"):
    ‚Äú[1m[22mIgnoring unknown parameters: `binwidth`, `bins`, and `pad`‚Äù



    
![png](output_204_1.png)
    


### 2. Statistiques bivari√©es avec les tables _description_indiv_ et _habitudes_indiv_

Quelques exemples de ce qu'il est possible de faire avec ```ggplot2``` :


```R
# Imc moyen par niveau de dipl√¥me

imc_par_diplome <- description_indiv %>% group_by(categorie_diplome) %>% summarise(imc_moyen=mean(imc,na.rm=TRUE))

ggplot(data=imc_par_diplome,aes(x=categorie_diplome,y=imc_moyen))+
geom_histogram(stat="identity")+
coord_flip()+
labs(title="IMC moyen par niveau de diplome",
     x="Cat√©gorie de diplome",
     y="IMC moyen")
```

    Warning message in geom_histogram(stat = "identity"):
    ‚Äú[1m[22mIgnoring unknown parameters: `binwidth`, `bins`, and `pad`‚Äù



    
![png](output_207_1.png)
    



```R
# Autoproduction par type d'agglom√©ration
description_x_habitudes <- description_indiv %>% left_join(habitudes_indiv,by="NOIND")
```


```R
autoprod_par_agglo <- description_x_habitudes %>% group_by(categorie_agglo) %>% summarise(part_autoprod=mean(autoproduction,na.rm=TRUE))
ggplot(data=autoprod_par_agglo,aes(x=categorie_agglo,y=part_autoprod))+
geom_histogram(stat="identity")+
labs(title="Part d'autoproduction par type d'agglom√©ration",
     x="Type d'agglom√©ration",
     y="Part d'autoproduction")
```

    Warning message in geom_histogram(stat = "identity"):
    ‚Äú[1m[22mIgnoring unknown parameters: `binwidth`, `bins`, and `pad`‚Äù



    
![png](output_209_1.png)
    


A vous de jouer, repr√©sentez le croisement entre le score d'ins√©curit√© d'alimentaire (**IA_score**, on peut en faire la moyenne) et les tranches de revenu (par exemple, **RUC_4cl** qu'on a recod√©e pr√©c√©demment, ou **revenu** qui donne le revenu disponible cod√© en plus de classes.)

Le dictionnaire des variables et des modalit√©s peut se trouver ici : https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf


```R
# Score d'IA par tranche de revenu

# TODO
# Score d'IA par tranche de revenu

scoreIA_par_tr_rev <- description_x_habitudes %>% group_by(categorie_ruc) %>% summarise(IA_score_moy=mean(IA_score,na.rm=TRUE))
ggplot(data=scoreIA_par_tr_rev,aes(x=categorie_ruc,y=IA_score_moy))+
geom_histogram(stat="identity")+
coord_flip()+
labs(title="Score IA moyen par tranche de revenu",
     x="Tranche de Revenu",
     y="score d'ins√©curit√© alimentaire")
```

    Warning message in geom_histogram(stat = "identity"):
    ‚Äú[1m[22mIgnoring unknown parameters: `binwidth`, `bins`, and `pad`‚Äù



    
![png](output_211_1.png)
    


Finalement, on se rend compte que la base est tr√®s riche et contient beaucoup de variables : beaucoup d'entre elles sont quantitatives, et on peut s'amuser √† repr√©senter leurs relations de corr√©lations en m√™me temps dans une matrice de corr√©lation.


```R
df_num <- description_x_habitudes %>% select(where(is.numeric))

df_num <- df_num %>% select(c("revenu","IA_score","imc","regime_vegetarien","poidsmax","fume","source_famille","jardin_potager","autoconsommation","consommation_bio"))

matrice_correlation <- model.matrix(~0+., data=df_num) %>% 
  cor(use="pairwise.complete.obs")
```

matrice_correlation %>%   ggcorrplot(show.diag=FALSE, type="lower", lab=TRUE, lab_size=7)

A vous d'ajouter les variables qui vous int√©ressent et √† multiplier les visualisations !
Les plus beaux graphes seront partag√©s √† l'issue du funathon.


```R
# TODO
#install.packages("DataExplorer")
library("DataExplorer")
plot_correlation(df_num, cor_args = list("use" = "pairwise.complete.obs"),title = "YEZ",theme_config = list(legend.position = "bottom", axis.text.x = element_text(size=20),
                                                                                                            axis.text.y = element_text(size=20))) 

```


    
![png](output_216_0.png)
    



```R

runExample("01_hello", host="0.0.0.0", port=5749)


```

    
    Listening on http://0.0.0.0:5749
    



```R
### 3. Cartographie
```

Pour la cartographie, on a besoin de fonds de carte. Ce sont des bases d'objets vectoriels. Par exemple, pour une carte de France par r√©gion, on aura une ligne par r√©gion avec un attribut g√©ographique renseignant les coordonn√©es du vecteur (ou polygone). Le package **cartiflette** nous permet de les t√©l√©charger directement et facilement.


```R
url <- "https://minio.lab.sspcloud.fr/projet-cartiflette/diffusion/shapefiles-test1/year%3D2022/administrative_level%3DREGION/crs%3D4326/FRANCE_ENTIERE%3Dmetropole/vectorfile_format%3D%27geojson%27/provider%3D%27IGN%27/source%3D%27EXPRESS-COG-CARTO-TERRITOIRE%27/raw.geojson"
```


```R
region <- sf::st_read(url)
```


```R
# Passons le fonds de carte dans le syst√®me de coordonn√©es de r√©f√©rence utilis√© pour la FRance, Lambert 93 (code : 2154) au lieu de WGS 84
region <- region %>% st_transform(2154)
```


```R
# Repr√©sentons les contours de notre fond de carte
plot(st_geometry(region))
```


```R
region$NOM_M
region <- region %>% mutate(NOM_M=ifelse(NOM_M=="CORSE", "PROVENCE-ALPES-COTE D'AZUR", NOM_M))
```

On va s'int√©resser aux fr√©quences de consommation de certains aliments, pr√©sentes dans la table fpq.


```R
description_x_fpq = left_join(description_indiv, fpq, by="NOIND")
```


```R
# Recodage de la variable r√©gion pour avoir les m√™mes noms que dans notre fond de carte

description_x_fpq <- description_x_fpq %>% mutate(region_recode=case_when(region_adm_12cl==1 ~ "ILE-DE-FRANCE",
                                                                         region_adm_12cl==2 ~ "NORMANDIE",
                                                                         region_adm_12cl==3 ~ "CENTRE-VAL DE LOIRE",
                                                                         region_adm_12cl==4 ~ "PAYS DE LA LOIRE",
                                                                         region_adm_12cl==5 ~ "BRETAGNE",
                                                                         region_adm_12cl==6 ~ "HAUTS-DE-FRANCE",
                                                                         region_adm_12cl==7 ~ "GRAND EST",
                                                                         region_adm_12cl==8 ~ "BOURGOGNE-FRANCHE-COMTE",
                                                                         region_adm_12cl==9 ~ "AUVERGNE-RHONE-ALPES",
                                                                         region_adm_12cl==10 ~ "PROVENCE-ALPES-COTE D'AZUR",
                                                                         region_adm_12cl==11 ~ "OCCITANIE",
                                                                         region_adm_12cl==12 ~ "NOUVELLE-AQUITAINE",))
```


```R
# Variable √† repr√©senter g√©ographiquement : nombre de bi√®re consomm√©es par mois. 

biere_par_region <- description_x_fpq %>% group_by(region_recode) %>% summarise(freq_conso_biere_moyenne=mean(BA_biere_freq_M,na.rm=TRUE))
biere_par_region
```


```R
# On cr√©e un petit tableau avec nos r√©gions et leurs attributs g√©ographiques, 
# et surtout la variable qu'on vient de calculer (c'est-√†-dire le nombre de bi√®res consomm√©es par mois par r√©gion en moyenne)

region_inca <- left_join(region,biere_par_region,by=c("NOM_M"="region_recode"))
```


```R
region_inca$freq_conso_biere_moyenne
```


```R
ggplot(data=region_inca) +
geom_sf(aes(fill=freq_conso_biere_moyenne)) +
scale_fill_continuous(low="yellow", high="Red", name="Nombre de bi√®res consomm√©es par mois en moyenne") +
labs(title="Nombre de bi√®res consomm√©es par mois en moyenne par r√©gion")
```

Maintenant, cr√©ez votre propre carte ! Vous pouvez regarder directement dans le dictionnaire des variables, ou bien vous aider des libell√©s.
Les fr√©quences en nombre de jours par mois finissent par _freq_M, et les indicatrices de consommation finissent par _ON (ces derni√®res valent 1 si le produit est consomm√© et 0 sinon). 

Par exemple, on peut choisir parmi les variables dans : ```colnames(fpq)```


```R
# TODO
```

## Partie 2 : Clustering d'individus

Premier point de contact : Antoine Palazzolo

Lorsque l'on pense au Machine Learning, les premiers exemples qui viennent en t√™te sont souvent des probl√®mes de r√©gression ou bien de classification.
Ces cas d'usage font partie d'une branche du ML appel√©e _apprentissage supervis√©_, qui requiert notamment d'avoir des donn√©es labellis√©es permettant aux diverses m√©thodes utilis√©es de comprendre la relation entre un ensemble de variables explicatives et une variable √† pr√©dire.

_L'apprentissage non supervis√©_ est une autre branche du ML qui ne consiste cette fois plus √† pr√©dire une variable donn√©e √† partir de donn√©es labellis√©es.
Au coeur de l'apprentissage non supervis√© on trouve notamment le __clustering__.
Cette fois-ci, le but est de cr√©er √† partir d'une population donn√©e un ensemble de clusters (ou paquets) d'individus regroup√©s par similarit√©, en utilisant de fa√ßon automatiques les caract√©ristiques les plus discriminantes de notre population. Ce sera peut-√™tre plus clair avec quelques exemples et applications :
- Une enseigne de retail poss√®de une centaine de magasins en France et souhaite regrouper ces derniers en une poign√©e de groupes qu'elle pourra approvisionner de la m√™me fa√ßon. Chaque groupe devra regrouper des magasins ayant des performances similaires et une client√®le proche. C'est un probl√®me de clustering.
- A partir d'une base de donn√©es regroupant les th√®mes de pr√©dilection de centaines de journalistes (ou bien leurs r√©f√©rences), on souhaite regrouper ces m√™mes journalistes en quelques cat√©gories au sein desquelles chaque individu aura une orientation politique proche de celles des autres.
- En fonction des caract√©ristiques physiques d'esp√®ces animales ou v√©g√©tales, on souhaite regrouper ces esp√®ces en un plus petit nombre de groupes.



Il existe plusieurs m√©thodes pour faire du clustering, les deux plus connues √©tant :
- Les [K-Moyennes](https://fr.wikipedia.org/wiki/K-moyennes) (ou K-Means), m√©thode la plus connue, bas√©e sur l'utilisation de centro√Ødes it√©r√©s
- Le [Clustering Ascendant Hi√©rarchique](https://fr.wikipedia.org/wiki/Regroupement_hi%C3%A9rarchique) (CAH), bas√© sur des regroupements en groupes de plus en plus grands, donnant par exemple lieu √† des visualisations sous forme de dendrogrammes (ressemblant aux arbres phylog√©n√©tiques de vos cours de SVT au lyc√©e)

Nous allons mettre en pratique ces deux m√©thodes dans ce sujet.

Une fois nos clusterings effectu√©s, l'un des enjeux est ensuite aussi de pouvoir interpr√©ter ces derniers :
- Quelles sont les caract√©ristiques les plus discriminantes dans la constitution des groupes ?
- Les clusters g√©n√©r√©s font-ils bien sens ? Que peut-on dire de ces groupes ?
- Quelles m√©thodes de visualisation sont les plus adapt√©es ?

Pour r√©pondre √† ces questions, un des outils principaux que nous pouvons utiliser est l'[Analyse en Composantes Principales](https://fr.wikipedia.org/wiki/Analyse_en_composantes_principales) (ACP), qui √† partir de l'ensemble initial des colonnes en cr√©e un ensemble de taille r√©duite qui maximise la discrimination des donn√©es les unes par rapport aux autres via ces nouvelles colonnes.
En r√©duisant la dimension √† moins de 3, on peut ainsi repr√©senter graphiquement les donn√©es de fa√ßon plus claire.

### 1. Preprocessing des donn√©es

Pour cette √©tude nous allons commencer par la table des habitudes individuelles.
Cette table contient les donn√©es des questionnaires auto-administr√©s relatifs aux volets ¬´ Habitudes alimentaires ¬ª et ¬´ Origine des aliments ¬ª.

Elle regroupe les informations suivantes : lieux et occasions de consommation, consommations hors-foyer et entre les repas, pr√©f√©rences alimentaires, pr√©sence de sel/beurre/sauce sur la table au moment des repas, lecture des √©tiquettes, sources d‚Äôinformations en alimentation, consommation de denr√©es animales crues et des cro√ªtes de fromage, pr√©paration des fruits et l√©gumes crus, sp√©cificit√©s de l‚Äôalimentation des enfants de 0 √† 35 mois (ex : allaitement (exclusif ou partiel), type de laits consomm√©s, diversification alimentaire, mat√©riaux des biberons et des t√©tines, pr√©paration, stockage et conservation des biberons de lait, mode de chauffage des laits et contenants utilis√©s), autoconsommation et utilisation de produits phytosanitaires au potager, consommation d‚Äôaliments issus de l‚Äôagriculture biologique et cuisson des aliments au barbecue.

Une fois le sujet termin√©, vous pourrez si vous le souhaitez reproduire cette partie avec d'autres des tables √† disposition.


```R
# Dimensions de habitudes_indiv
n_rows <- nrow(habitudes_indiv)
n_cols <- ncol(habitudes_indiv)

# Affichage des dimensions
print(paste("Nombre de lignes :", n_rows))
print(paste("Nombre de colonnes :", n_cols))
```


```R
head(habitudes_indiv, 3)
```

#### Etape 1 : Analyse exploratoire & s√©lection de variables

Regardons d√©j√† √† quoi ressemblent nos donn√©es en pratique. En utilisant dplyr, pouvez-vous dire :
- Combien y a-t-il d'individus et de variables ?
- Combien de variables pr√©sentent des valeurs vides ? En quelle proportion ?
- Y a-t-il des variables qui ont la m√™me valeur pour tous les individus ? Seront-elles utiles pour la discrimination des observations dans le clustering ?
- Y a-t-il des variables qui n'ont pas de sens pour la caract√©risation d'un groupe ? Cela comprend par exemple les identifiants.
- Quels sont les types des variables ? Combien de variables non-num√©riques ? En pratique nous allons ici nous focaliser uniquement sur les donn√©es num√©riques de la table.


```R
# A vous de jouer !

# TODO
```

A partir des analyses que vous venez de r√©aliser, vous devriez avoir une meilleure id√©e de quoi garder dans la table pour appliquer les m√©thodes de clustering. Cr√©ez donc ```habitudes_indiv_clustering_1``` √† partir de ```habitudes_indiv``` en retirant toutes les colonnes g√™nantes ou inutiles :

<details>
<summary> Si besoin, d√©rouler pour r√©v√©ler les indications plus d√©taill√©es :</summary>
<br>

Il vous faudra donc, a minima :
- Retirer les colonnes d'identifiants
- Retirer les colonnes vides
- Conserver uniquement les colonnes num√©riques

Pour aller plus loin, retirez les colonnes √† moins de 2 valeurs distinctes.

</details>



```R
habitudes_indiv_clustering_1 <- data.frame() # TODO
```


```R
# Dimensions de habitudes_indiv
n_cols <- ncol(habitudes_indiv_clustering_1)

# Affichage des dimensions
print(paste("Nombre de colonnes :", n_cols))
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
# S√©lectionner les caract√©ristiques pour le clustering
habitudes_indiv_clustering_1 <- habitudes_indiv %>%
  select(-c(POPULATION, NOIND, periode_reference)) %>%  # Identifiants
  select_if(function(col) any(!is.na(col))) %>%  # Colonnes vides
  select_if(is.numeric) %>%  # Colonnes num√©riques √† garder
  select_if(function(col) length(unique(col)) > 1)  # On retire les colonnes avec moins de 2 valeurs distinctes
```

</details>


#### Etape 2 : Imputation

Comme vous l'avez peut-√™tre vu, si l'on cherche √† retirer toutes les lignes ou colonnes avec au moins une valeur manquante, il ne reste plus grand-chose √† la table...
Nous allons donc les garder, d'autant plus que cela ne les emp√™che pas de contenir de l'information importante.

Dans ce cas comment traiter les NaNs ?
Il existe une m√©thode pour les remplacer par une valeur num√©rique, il s'agit de l'__[imputation](https://fr.wikipedia.org/wiki/Imputation_(statistique))__.

Plusieurs m√©thodes d'imputation existent : remplacer les valeurs manquantes par la moyenne de la colonne, par une valeur issue de r√©gression lin√©aire, de r√©gression stochastique, etc.

Dans notre cas particulier, la plupart des variables sont binaires, des r√©ponses Oui/Non √† une question.
Une m√©thode que nous pouvons donc utiliser (mais d'autres marcheraient tr√®s bien aussi) est l'imputation par la valeur non vide la plus fr√©quente de la colonne.

En termes d'interpr√©tation, cela revient √† simplifier le probl√®me en consid√©rant que les non-r√©pondants auraient r√©pondu la m√™me chose que la majorit√© des r√©pondants, quitte √† ce que cela m√®ne √† de possibles erreurs.
Par exemple, les r√©pondants "Homme" ont peu de chances de r√©pondre "Oui" √† l'allaitement, mais c'est une solution qui fonctionne tout de m√™me en g√©n√©ral tr√®s bien.

<br>

A pr√©sent, appliquez cette strat√©gie d'imputation sur la table ```habitudes_indiv_clustering_1``` pour donner naissance √† ```habitudes_indiv_clustering_2```.


```R
habitudes_indiv_clustering_2 <- data.frame() # TODO
```


```R
# Dimensions de habitudes_indiv
n_cols <- ncol(habitudes_indiv_clustering_2)

# Affichage des dimensions
print(paste("Nombre de colonnes :", n_cols))
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
Mode <- function(x) {
  non_missing_values <- x[!is.na(x)]
  ux <- unique(non_missing_values)
  ux[which.max(tabulate(match(non_missing_values, ux)))]
}

# Remplacer les valeurs manquantes (NaN) par le mode
habitudes_indiv_clustering_2 <- habitudes_indiv_clustering_1 %>%
  mutate_all(~ifelse(is.na(.), Mode(.), .)) %>%
select_if(function(col) length(unique(col)) > 1)  # On re-retire les colonnes avec moins de 2 valeurs distinctes pour s'√©viter des erreurs par la suite
```

</details>


#### Etape 3 : Normalisation des colonnes

Pour la plupart des m√©thodes que nous allons utiliser, nous ne souhaitons pas n√©cessairement donner plus d'importance √† une colonne qu'√† une autre.
Or pour plusieurs des fonctions que nous allons manipuler, le poids affect√© √† une colonne peut d√©pendre de sa moyenne ou de sa variance.

Ici, les questions √©tant pour la plupart binaires, nous ne voulons pas qu'une question avec davantage de r√©ponses positives ait une importance plus grande qu'une autre.
Nous devons donc renormaliser les colonnes pour corriger ce probl√®me.

A vous de jouer : renormalisez l'ensemble des colonnes pour amener leur moyenne √† 0 et leur variance √† 1. Vous stockerez le r√©sultat dans le tableau ```habitudes_indiv_clustering_3```.


```R
habitudes_indiv_clustering_3 <- data.frame() # TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
# Normalisation des colonnes
habitudes_indiv_clustering_3 <- scale(habitudes_indiv_clustering_2)
```

</details>


#### Etape 4 : Gestion des outliers

Dans ce type de questionnaire il n'est pas rare de trouver des observations aberrantes, par exemple en raison d'individus r√©pondant de fa√ßon absurde aux questions.
De fa√ßon g√©n√©rale, si la base de donn√©es est suffisamment grande et que l'on ne s'int√©resse pas n√©cessairement √† chaque individu, une bonne pratique peut √™tre de retirer les outliers de notre base.
Cela permet en effet de limiter les risques d'avoir des clusters √† un seul individu ne repr√©sentant rien d'int√©ressant ou d'avoir des visualisations d√©form√©es par une observation tr√®s loin par rapport aux autres.

A vous de jouer : retirez les outliers de la table ```habitudes_indiv_clustering_3```, disons 3% des observations, et stockez le r√©sultat dans la table ```habitudes_indiv_clustering_4```.

Vous pouvez importer et utiliser le package ```isotree```, notamment les m√©thodes ```isolation.forest()``` et ```predict()```.


```R
habitudes_indiv_clustering_4 <- data.frame() # TODO
```


```R
# Dimensions de habitudes_indiv
n_rows <- nrow(habitudes_indiv_clustering_4)

# Affichage des dimensions
print(paste("Nombre de lignes restantes :", n_rows))
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
library(isotree)

outlier_detector <- isolation.forest(habitudes_indiv_clustering_3)
is_outlier_scores <- predict(outlier_detector, habitudes_indiv_clustering_3)
sorted_oulier_scores <- order(is_outlier_scores)

nb_observations_to_keep <- round(0.97 * nrow(habitudes_indiv_clustering_3))
habitudes_indiv_clustering_4 <- habitudes_indiv_clustering_3[sorted_oulier_scores[1:nb_observations_to_keep], ] %>%
select_if(function(col) length(unique(col)) > 1)  # On re-retire les colonnes avec moins de 2 valeurs distinctes pour s'√©viter des erreurs par la suite
```

</details>

Si vous le souhaitez, vous pourrez dans un second temps reproduire la suite sans retirer les outliers pour comparer les r√©sultats obtenus.

<br>

Vous avez √† pr√©sent termin√© le preprocessing de la table pour la partie Clustering.
Libre √† vous de rajouter des op√©rations suppl√©mentaires si vous en voyez le besoin.
Sinon nous pouvons rentrer dans le vif du sujet.

Pour simplifier les notations, ex√©cutez la cellule ci-dessous :


```R
habitudes_indiv_clustering <- as.data.frame(habitudes_indiv_clustering_4) %>%
select_if(function(col) length(unique(col)) > 1)  # On re-retire les colonnes avec moins de 2 valeurs distinctes pour s'√©viter des erreurs par la suite

dim(habitudes_indiv_clustering)
```

### 2. Le clustering en lui-m√™me

Dans cette partie, nous allons mettre en pratique les 2 m√©thodes de clustering les plus classiques :
- Les K-Moyennes (ou K-Means)
- Le Clustering Ascendant Hi√©rarchique (CAH)

#### K-Moyennes

Dans ce sujet, nous ne revenons pas sur la th√©orie derri√®re l'algorithme du K-Means.
Donc si vous √™tes int√©ress√©s pour savoir ce qui se passe derri√®re l'utilisation du package en bo√Æte noire, la documentation sur cette th√©matique est largement disponible sur Internet.

##### Choisir le nombre de clusters

Une particularit√© des K-moyennes est qu'il faut choisir en amont de l'application de l'algorithme le nombre de clusters (ou de centro√Ødes) ```k```, a priori sans savoir quel serait le nombre optimal.
Il existe plusieurs m√©thodes pour faire ce choix :
- S'il existe des contraintes m√©tier ou des interpr√©tations relatives au "monde r√©el" imposant une valeur de ```k```
- En utilisant la m√©thode dite du __coude__, qui est la fa√ßon la plus simple d'avoir une id√©e de ```k``` √† utiliser.
    + Le principe est de lancer le K-means avec plusieurs valeurs de ```k```, repr√©senter une mesure de la distance moyenne intra-clusters en fonction de ```k``` et trouver le premier point d'inflexion
    + En revanche, le ```k``` renvoy√© n'est pas toujours stable et parfois peu pertinent.
- En utilisant la m√©thode dite de __silhouette__, m√©thode a priori plus fine mais un peu plus complexe que celle du coude
    + Le score √† maximiser par rapport √† ```k``` est cette fois la moyenne d'une mesure de la similitude d‚Äôune observation √† l‚Äôint√©rieur d‚Äôun groupe par rapport √† d‚Äôautres groupes pour chaque point

A titre d'exemple, utilisez la m√©thode du coude pour trouver le nombre optimal de clusters pour les donn√©es de ```habitudes_indiv_clustering```. On cherchera un ```k``` compris entre 1 et 10.

Vous pouvez importer et utiliser la fonction ```fviz_nbclust()``` du package ```factoextra```.


```R
# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
library(factoextra)
library(cluster)

# M√©thode du coude
elbow_method <- fviz_nbclust(habitudes_indiv_clustering, kmeans, method = "wss", k.max = 10)
elbow_method
```

</details>

A pr√©sent faites la m√™me chose mais avec la m√©thode de Silhouette :


```R
# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
# M√©thode de Silhouette
silhouette_method <- fviz_nbclust(habitudes_indiv_clustering, kmeans, method = "silhouette", k.max = 10)
silhouette_method
```

</details>

Quel est le ```k``` obtenu ? Cette valeur reste-t-elle la m√™me si vous lancez la m√©thode plusieurs fois ?

S'il n'y a pas de point d'inflexion (ou coude) bien d√©fini sur le premier graphique produit, la valeur peut souvent varier. Pour la suite du sujet, nous conserverons une valeur fixe, que vous pourrez modifier par la suite si vous le souhaitez. Ex√©cutez la ligne ci-dessous :


```R
k_kmeans <- 3
```

##### Le clustering en lui-m√™me

Une fois les donn√©es pr√©process√©es et le ```k``` d√©termin√©, clusteriser les donn√©es n'est plus tr√®s difficile.

Cr√©ez le vecteur ```clusters_kmeans``` des clusters obtenus par la m√©thode des K-moyennes :


```R
# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
k_moyennes <- kmeans(habitudes_indiv_clustering, centers = k_kmeans, nstart = 20)

# Assignation des clusters
clusters_kmeans <- k_moyennes$cluster
```

</details>

F√©licitations, vous avez d√©sormais vos clusters !
Pouvez-vous dire quelle est la taille de chacun ? Ces valeurs sont-elles proches les unes des autres ? Pouvez-vous d√©j√† interpr√©ter vos r√©sultats ?


```R
# TODO
```

On a certes obtenu nos clusters, mais tout cela n'est pas encore tr√®s visuel...

Mais pas de panique, plus que quelques cellules √† attendre pour passer √† la visualisation par ACP !

#### Clustering Ascendant Hi√©rarchique

Avant de passer √† la visualisation, nous allons nous attarder sur une autre m√©thode de clustering, √† peu pr√®s √©quivalente aux K-moyennes en termes de performances, mais dont les r√©sultats sont beaucoup plus visuels : le [CAH](https://www.xlstat.com/fr/solutions/fonctionnalites/classification-ascendante-hierarchique-cah). Comment est-ce que √ßa marche ?

- On commence par calculer la dissimilarit√© entre nos N individus, ie leur distance deux √† deux dans l'espace de nos variables
- Puis on regroupe les deux individus dont le regroupement minimise un crit√®re d'agr√©gation donn√©, cr√©ant ainsi une classe comprenant ces deux individus.
- On calcule ensuite la dissimilarit√© entre cette classe et les N-2 autres individus en utilisant le crit√®re d'agr√©gation.
- Puis on regroupe les deux individus ou classes d'individus dont le regroupement minimise le crit√®re d'agr√©gation.
- On continue ainsi jusqu'√† ce que tous les individus soient regroup√©s.

Ces regroupements successifs produisent un arbre binaire de classification (_dendrogramme_), dont la racine correspond √† la classe regroupant l'ensemble des individus.
Ce dendrogramme repr√©sente une hi√©rarchie de partitions.
On peut alors choisir une partition en tronquant l'arbre √† un niveau donn√©, le niveau d√©pendant soit des contraintes de l'utilisateur, soit de crit√®res plus objectifs.

<br>

Dans ce sujet, nous allons nous limiter √† la m√©thode d'agr√©gation la plus standard, dite de __Ward__.
Cr√©ez les regroupements successifs mentionn√©s plus haut.
Le r√©sultat tient en une ligne.


```R
regroupements <- '' # TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
regroupements <- hclust(dist(habitudes_indiv_clustering), method = 'ward.D')
```

</details>

Maintenant les regroupements effectu√©s, vous pouvez dessiner le dendrogramme les repr√©sentant.
Pour des contraintes de lisibilit√©, nous vous recommandons si vous y arrivez de limiter l'affichage de l'arbre √† une profondeur de 6.

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
plot(regroupements, hang = -1, labels = FALSE)

```

</details>

Si tout s'est bien pass√© jusqu'ici, vous devriez avoir un magnifique dendrogramme sous les yeux !

Cependant une question demeure : jusque-l√† la probl√©matique du nombre de clusters √† utiliser ne s'est toujours pas pos√©e, comment allons-nous choisir maintenant ?
Encore une fois, des contraintes du monde r√©el peuvent venir diriger le choix.
Si ce n'est pas le cas, on peut faire par rapport √† l'allure du dendrogramme, en choisissant une coupe horizontale de l'arbre coh√©rente.
Cette coupe d√©termine alors les clusters finaux.

En utilisant la fonction ```cutree()```, r√©alisez cette coupe du dendrogramme au niveau ```k_cah = 3``` pour cr√©er le vecteur ```clusters_cah``` des clusters obtenus par CAH. Une fois les clusters g√©n√©r√©s, que pouvez-vous en dire ? Est-ce coh√©rent avec votre dendrogramme ?

Une fois le reste du sujet effectu√©, vous pourrez √©galement reprendre cette partie avec ```k_cah = 4```.


```R
k_cah <- 3  # Nombre de clusters souhait√©

# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
clusters_cah <- cutree(regroupements, k = k_cah)

```

</details>

Maintenant les clusters obtenus par deux m√©thodes diff√©rentes, il est temps de passer √† la visualisation !

### 3. Visualisations et interpr√©tations

#### R√©aliser l'ACP

La m√©thode la plus simple pour visualiser nos clusters serait de repr√©senter chaque individu dans l'espace √† N dimensions des variables de la table, et colorier chaque individu en fonction de son cluster.
On pourrait alors bien diff√©rencier les variables les plus discrimantes et les diff√©rents groupes.
Un seul probl√®me ici : d√®s que N > 3, nous avons du mal √† repr√©senter le r√©sultat de fa√ßon intelligible...

C'est l√† qu'intervient __l'Analyse en Composantes Principales__ ([ACP](https://www.xlstat.com/fr/solutions/fonctionnalites/analyse-en-composantes-principales-acp)), qui permet de projeter notre espace √† haute dimension dans un espace de dimension plus petite.
La contrainte majeure de la projection est de pouvoir conserver le maximum d'information (mesur√©e par la variance totale de l'ensemble de donn√©es) dans notre nombre r√©duit de dimensions, appel√©es composantes principales.
En se limitant √† 2 ou 3 dimensions, on peut ainsi se repr√©senter visuellement les relations entre les observations avec une perte de fiabilit√© minimale.

Dans notre situation, on peut esp√©rer que les clusters d√©termin√©s dans notre espace √† N dimensions se diff√©rencient bien sur notre projection par ACP, et que la composition des composantes principales en fonction des variables initiales permette d'interpr√©ter les clusters obtenus. Nous allons donc tester cette hypoth√®se !

<br>

Nous allons commencer par le calcul des 3 composantes principales. Cr√©ez :
- Un dataframe ```projection_individus``` correspondant √† la projection des individus de ```habitudes_indiv_clustering``` dans l'espace des composantes principales. Ce dataframe aura donc 3 colonnes, que l'on pourra nommer si ce n'est pas automatiquement le cas [PC1, PC2, PC3].
- Un dataframe ```composantes_principales``` avec les m√™mes colonnes que ```projection_individus```, mais o√π la ligne i correspond √† la contribution relative de la variable i √† chacune des composantes de l'ACP.

Vous pourrez vous servir de la fonction ```prcomp()``` du package de base R.


```R
nb_composantes_principales <- 3

# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
nb_composantes_principales <- 3

acp <- prcomp(habitudes_indiv_clustering, retx = TRUE, rank. = nb_composantes_principales)
projection_individus <- data.frame(acp$x)
composantes_principales  <- data.frame(acp$rotation)
```

</details>

Maintenant l'ACP termin√©e, nous allons t√¢cher d'interpr√©ter les composantes principales obtenues.
En effet, la combinaison lin√©aire des colonnes donnant naissance √† nos nouveaux axes a souvent un "sens" dans le monde r√©el :
- Soit parce qu'une petite poign√©e de variables repr√©sente la majorit√© de la composante
- Soit parce que la plupart des colonnes intervenant dans la composante somm√©e se combinent bien pour former une interpr√©tation naturelle.

Ici, cela pourrait par exemple √™tre :
- La 1√®re composante quasiment √©gale √† une somme des variables "Mange bio", "Mange de saison" et "Mange local", montrant ainsi que l'axe le plus discriminant serait le fait pour un individu de se nourrir de fa√ßon plus ou moins √©cologique.
- La 2√® composante d√©finie comme la somme pour tous les sports de la variable "Pratique x sport r√©guli√®rement", donnant ainsi un second axe discriminant les individus plus ou moins sportifs

Voyons ce que cela donne sur nos donn√©es. En utilisant la table ```composantes_principales```, repr√©sentez les 20 variables les plus importantes (en termes de poids absolu) pour la 1√®re composante de l'ACP, ainsi que leur contribution relative √† la composante. Plusieurs approches sont possibles ici, par exemple en fonction de si vous cherchez √† repr√©senter les contributions en valeur absolue ou non (autoriser les contributions n√©gatives est plus int√©ressant pour l'interpr√©tation des axes).


```R
nb_top_features <- 20

# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√© - Version simple</b></font> </summary>
<br>

```r
nb_top_features <- 20

fviz_contrib(acp, choice = "var", axes = 1, sort.val="desc", top = 20,
             title = paste(nb_top_features, "variables les plus repr√©sent√©es sur la PC1 - Contributions absolues"))

```

</details>

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√© - Version compl√®te</b></font> </summary>
<br>

```r
nb_top_features <- 20

# S√©lectionner les 20 caract√©ristiques les plus importantes pour PC1
pc1_features_abs <- abs(composantes_principales %>% select(PC1))
pc1_top_features_abs <- head(pc1_features_abs %>% arrange(desc(PC1)), nb_top_features)
pc1_top_features <- pc1_top_features_abs %>%
    rename(PC1_abs = PC1) %>%
    merge(composantes_principales, by = 'row.names', all = FALSE) %>%
    select(Row.names, PC1)

par(mar = c(5, 20, 5, 2))
barplot(pc1_top_features$PC1,
        horiz = TRUE,
        names.arg = pc1_top_features$Row.names,
        las = 1,
        main = paste(nb_top_features, "variables les plus repr√©sent√©es sur la PC1 - Contribution relative"),
        xlab = "Poids relatif",
        ylab = "Variables")

```

</details>

Faites ensuite la m√™me chose pour PC2 et pour PC3.


```R
# TODO
```

A pr√©sent, comment pouvez-vous interpr√©ter vos r√©sultats ?
√ätes-vous capables de donner un sens aux combinaisons lin√©aires obtenues ?
Peut-on renommer nos variables "PC1", "PC2, "PC3" ?

Si vous ne vous souvenez plus de la signification des variables, vous pouvez retrouver le dictionnaire des variables ici : https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

Il n'est pas garanti que vous retrouviez exactement les m√™mes r√©sultats, mais voici une proposition d'interpr√©tation suite √† l'ex√©cution des codes du corrig√© :
- PC1 : Une mesure agr√©g√©e repr√©sentant √† quel point l'individu a tendance √† produire lui-m√™me ce qu'il mange
    - Nombreuses variables commen√ßant par "autoproduction" et "autoconso" avec des poids positifs
- PC2 : Une mesure agr√©g√©e repr√©sentant √† quel point l'individu a tendance √† manger bio
    - Nombreuses variables contenant le mot "bio" avec des poids positifs
- PC3 : Plus difficile √† interpr√©ter, une mesure agr√©g√©e de pr√©f√©rences alimentaires li√©es aux produits frais
    - A quel point l'individu est-il prompt √† manger frais (fruits & l√©gumes, produits laitiers) ?

</details>

#### Et le clustering dans tout √ßa ?

Nous avons notre projection sur 2 ou 3 dimensions, nous avons interpr√©t√© ces nouveaux axes, il s'agit donc maintenant de faire ce pour quoi l'ACP a initialement √©t√© r√©alis√©e : l'observation des clusters.

Pour commencer, cr√©ez la table ```projection_individus_et_clusters``` concat√©nant les tables ```projection_individus```, ```clusters_kmeans``` et ```clusters_cah```:


```R
# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
projection_individus_et_clusters <- projection_individus

projection_individus_et_clusters$cluster_kmeans <- clusters_kmeans
projection_individus_et_clusters$cluster_cah <- clusters_cah
```

</details>

A pr√©sent, il ne vous reste plus qu'√† repr√©senter vos individus dans l'espace __2D__ g√©n√©r√© par les composantes PC1 et PC2. Concentrons-nous d'abord sur les clusters par K-moyennes : vous colorierez donc vos points en fonction de la valeur de la colonne 'cluster_kmeans'. A vous de jouer !

Bonus : N'h√©sitez pas √† renommer vos axes pour leur donner des noms plus explicites en fonction des interpr√©tations que vous avez faites pr√©c√©demment.


```R
# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√©</b></font> </summary>
<br>

```r
# Afficher le graphique des clusters en 2D
plot(projection_individus_et_clusters$PC1, projection_individus_et_clusters$PC2,
     col = projection_individus_et_clusters$cluster_kmeans,
     pch = 16,
     main = "Individus group√©s par tendances alimentaires",
     xlab = "PC1 - Production & consommation de sa propre nourriture",
     ylab = "PC2 - Consommation d'aliments bio")

legend("topright", legend = unique(projection_individus_et_clusters$cluster_kmeans),
       col = unique(projection_individus_et_clusters$cluster_kmeans),
       pch = 16,
       title = "Cluster (K-moyennes)")
```

</details>

Plut√¥t cool, non ?
La grande question maintenant : vos clusters se diff√©rencient-ils bien sur votre visualisation ? Si les choses sont bien faites, il devrait y avoir peu de superposition des diff√©rents groupes.

Pouvez-vous maintenant caract√©riser vos clusters en fonction de leur position sur votre graphe ? Vous avez ainsi vos _individus-types_ permettant de sch√©matiser votre population.

A pr√©sent, faites pareil sur les clusters obtenus par CAH, obtenez-vous exactement les m√™mes clusters ? L'interpr√©tation que vous avez faite change-t-elle ?


```R
# TODO
```

Pour terminer, quid d'utiliser notre 3√® composante principale dans notre repr√©sentation graphique ?
Cherchez sur Internet comment r√©aliser cette fois un graphe en __3 dimensions__ dans lequel repr√©senter vos individus.
Comment √©volue l'apparence de vos clusters ?


```R
# TODO
```

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√© - Version statique</b></font> </summary>
<br>

```r
# Afficher le graphique des clusters en 3D
library("scatterplot3d")

xs <- projection_individus_et_clusters$PC1
ys <- projection_individus_et_clusters$PC2
zs <- projection_individus_et_clusters$PC3

color <- projection_individus_et_clusters$cluster_kmeans

scatterplot3d(xs, ys, zs,
              color = color,
              pch = 16,
              main = "Individus group√©s par tendances alimentaires",
              xlab = "PC1 - Production & consommation de sa propre nourriture",
              ylab = "PC2 - Consommation d'aliments bio",
              zlab = "PC3 - Pr√©f√©rences produits frais")

```

</details>

<details>
<summary> <font size=2 color="red"><b>D√©rouler pour r√©v√©ler le corrig√© - Version interactive</b></font> </summary>
<br>

```r
library("plotly")

xs <- projection_individus_et_clusters$PC1
ys <- projection_individus_et_clusters$PC2
zs <- projection_individus_et_clusters$PC3

color <- projection_individus_et_clusters$cluster_kmeans

# Cr√©er un objet plotly avec les coordonn√©es x, y, z et la couleur
plot <- plot_ly(x = xs, y = ys, z = zs, color = color, type = "scatter3d", mode = "markers")

# D√©finir les √©tiquettes des axes
plot <- layout(plot, scene = list(xaxis = list(title = "PC1 - Production & consommation de sa propre nourriture"),
                                  yaxis = list(title = "PC2 - Consommation d'aliments bio"),
                                  zaxis = list(title = "PC3 - Pr√©f√©rences produits frais")))

# Afficher le graphique interactif
print(plot)
```

<br>

Si jamais le graphique n'est pas lisible dans l'output de la cellule, clic droit sur la cellule puis "Enable new view for cell output"

</details>

### 4. Pour aller plus loin

Vous avez √† pr√©sent termin√© la partie clustering du sujet. Si vous souhaitez aller plus loin, vous pouvez :

- Parcourir utilitR, et notamment la page [Analyse de donn√©es](https://www.book.utilitr.org/03_fiches_thematiques/fiche_analyse_de_donnees) et reproduire les visualisations pr√©sent√©es sur les donn√©es de la table ```habitudes_indiv```. Vous pouvez √©galement reprendre le sujet et utiliser des packages comme ```factoMineR``` ou bien ```factoExtra``` l√† o√π les corrig√©s ont √©t√© faits sans.
    + Parvenez-vous ainsi √† affiner vos conclusions pr√©c√©dentes ?

<br>

- Reproduire toutes les ex√©cutions en retirant seulement l'une des √©tapes du preprocessing, comme par exemple le traitement des outliers. Comment √©voluent alors les clusters et visualisations ?
    + Retirer les outliers peut souvent conduire √† la cr√©ation de clusters constitu√©s d'un seul individu, tr√®s √©loign√© des autres sur l'ACP. Il faut donc traiter ce type d'observations √† part ou bien augmenter le nombre de clusters pour compenser.

<br>
 
- Reproduire toutes les ex√©cutions en changeant le nombre de clusters ```k``` : comment √©voluent les clusters ? Que cela donne-t-il sur les ACP ?
    + Le cas ```k = 4``` est particuli√®rement int√©ressant : les clusters semblent se superposer sur les visualisations en 2D, mais on se rend compte lors de la visualisation 3D que les clusters pr√©tendumment superpos√©s se diff√©rencient en fait tr√®s bien si l'on rajoute la 3√® composante principale. Cela permet alors de caract√©riser encore plus finement nos individus types.

<br>

- Reproduire toutes les ex√©cutions sur une autre table que celles des habitudes alimentaires.
    + Nous vous recommandons par exemple d'essayer avec :
        - ```actphys_sedent``` : questionnaire sur l'activit√© physique des r√©pondants
        - ```fpq``` : questionnaire sur le fr√©quential alimentaire des individus
    + Comment les clusters s'interpr√®tent-ils alors ? Quels sont nos individus-types ?
    + Si vous souhaitez aller encore plus loin, vous pouvez faire une jointure sur les diff√©rentes tables et op√©rer le clustering sur la table jointe afin de voir quelles sont les caract√©ristiques les plus discriminantes.
    + Pour les autres tables, attention √† ne bien garder que des variables num√©riques, et par exemple faire du _one-hot encoding_ sur les variables cat√©gorielles cod√©es sur des nombres entre 1 et 10.


```R
# TODO
```

# Fin :)

Si vous voulez toucher √† de la r√©gression et de l'apprentissage supervis√©, n'h√©sitez pas √† revisiter le sujet en Python !
